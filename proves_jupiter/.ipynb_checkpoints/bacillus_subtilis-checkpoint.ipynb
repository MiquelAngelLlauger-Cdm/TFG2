{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba3d378-5b3e-4bcb-96a0-c502ac609fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>taxaID</th>\n",
       "      <th>locus</th>\n",
       "      <th>gene</th>\n",
       "      <th>essentiality</th>\n",
       "      <th>pmid</th>\n",
       "      <th>Ref_db</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199</td>\n",
       "      <td>224308</td>\n",
       "      <td>BSU41040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>12682299</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199</td>\n",
       "      <td>224308</td>\n",
       "      <td>BSU41030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>12682299</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199</td>\n",
       "      <td>224308</td>\n",
       "      <td>BSU41020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>12682299</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199</td>\n",
       "      <td>224308</td>\n",
       "      <td>BSU41010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>12682299</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199</td>\n",
       "      <td>224308</td>\n",
       "      <td>BSU41000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>12682299</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  taxaID     locus  gene essentiality      pmid  Ref_db\n",
       "0      199  224308  BSU41040   NaN           NE  12682299     NaN\n",
       "1      199  224308  BSU41030   NaN           NE  12682299     NaN\n",
       "2      199  224308  BSU41020   NaN           NE  12682299     NaN\n",
       "3      199  224308  BSU41010   NaN           NE  12682299     NaN\n",
       "4      199  224308  BSU41000   NaN           NE  12682299     NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import cobra\n",
    "import numpy as np\n",
    "from cobra.flux_analysis import single_gene_deletion\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"Bacillus subtilis subsp. subtilis str. 168_genes.csv\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e4e24da-8fa5-4275-ac4a-eb02b55223c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bacillus_ground_truth = data[['locus', 'essentiality']].copy()\n",
    "essentials = bacillus_ground_truth[bacillus_ground_truth['essentiality'] == 'E']\n",
    "\n",
    "essentials_list = list(set(essentials[\"locus\"]))\n",
    "essentials_df = pd.DataFrame({\"ids\": essentials_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19ce8b86-6ff4-4d0a-a686-194c012817b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BSU01390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BSU16520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BSU23410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BSU01400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BSU24410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>BSU24420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>BSU01200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>BSU11810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>BSU17380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>BSU25670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ids\n",
       "0    BSU01390\n",
       "1    BSU16520\n",
       "2    BSU23410\n",
       "3    BSU01400\n",
       "4    BSU24410\n",
       "..        ...\n",
       "357  BSU24420\n",
       "358  BSU01200\n",
       "359  BSU11810\n",
       "360  BSU17380\n",
       "361  BSU25670\n",
       "\n",
       "[362 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essentials_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8ed3835e-00d3-48df-af4a-0a86bebba8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{BSU15810, BSU23180, BSU01390, BSU25270, BSU01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ids\n",
       "0  {BSU15810, BSU23180, BSU01390, BSU25270, BSU01..."
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c07be549-63e1-4272-847b-4d8b78ca673b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of essential genes: 171\n",
      "            ids        growth   status\n",
      "21   {BSU40420} -2.229021e-14  optimal\n",
      "34   {BSU28270} -5.362528e-17  optimal\n",
      "40   {BSU14190} -3.076827e-16  optimal\n",
      "50   {BSU14000} -4.228266e-16  optimal\n",
      "58   {BSU25660}  1.242323e-18  optimal\n",
      "..          ...           ...      ...\n",
      "832  {BSU06500} -2.467679e-14  optimal\n",
      "833  {BSU06530}  4.491758e-16  optimal\n",
      "835  {BSU17390}  1.125393e-16  optimal\n",
      "836  {BSU21810}  0.000000e+00  optimal\n",
      "843  {BSU16550}  0.000000e+00  optimal\n",
      "\n",
      "[171 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "deletion_results = single_gene_deletion(model)\n",
    "\n",
    "threshold = 0.05 \n",
    "essential_genes = deletion_results[deletion_results['growth'] < threshold]\n",
    "\n",
    "print(f\"Number of essential genes: {len(essential_genes)}\")\n",
    "print(essential_genes)\n",
    "flat_essential_genes = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71b2a96f-7bb5-40f2-bb45-cae527c72aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: iYO844\n",
      "Number of reactions: 1250\n",
      "Number of metabolites: 990\n",
      "Number of genes: 844\n"
     ]
    }
   ],
   "source": [
    "model_path = \"iYO844.json\"\n",
    "model = cobra.io.load_json_model(model_path)\n",
    "print(f\"Model: {model.id}\")\n",
    "print(f\"Number of reactions: {len(model.reactions)}\")\n",
    "print(f\"Number of metabolites: {len(model.metabolites)}\")\n",
    "print(f\"Number of genes: {len(model.genes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6f4ef04-38e5-4076-b546-8f27302c3e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stoichiometric matrix dimensions: (990, 1250)\n",
      "Number of metabolites: 990\n",
      "Number of reactions: 1250\n"
     ]
    }
   ],
   "source": [
    "S = cobra.util.array.create_stoichiometric_matrix(model)\n",
    "S_df = pd.DataFrame(S, \n",
    "                    index=[met.id for met in model.metabolites], \n",
    "                    columns=[rxn.id for rxn in model.reactions])\n",
    "S_df.to_csv('iYO844_stoichiometry.csv')\n",
    "print(f\"Stoichiometric matrix dimensions: {S.shape}\")\n",
    "print(f\"Number of metabolites: {S.shape[0]}\")\n",
    "print(f\"Number of reactions: {S.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17e9c1f5-8f3e-4106-ad9c-64300502ae59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growth rate: 0.11796638932331782\n"
     ]
    }
   ],
   "source": [
    "solution = model.optimize()\n",
    "\n",
    "#Vegem les solucions\n",
    "print(f\"Growth rate: {solution.objective_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fbdeb3f-2ed6-4026-a209-3477a9f0befe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximize\n",
      "1.0*BIOMASS_BS_10 - 1.0*BIOMASS_BS_10_reverse_8788b\n"
     ]
    }
   ],
   "source": [
    "print(model.objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d26a6cf5-9df0-49fd-ac5c-9f469fea6f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = solution.fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b685947-ff59-463e-8289-12b86a862399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reaction</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "      <th>is_reversible</th>\n",
       "      <th>name</th>\n",
       "      <th>flux</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EX_etha_e</th>\n",
       "      <td>EX_etha_e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Ethanolamine exchange</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_drib_e</th>\n",
       "      <td>EX_drib_e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Deoxy D Ribose exchange</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_csn_e</th>\n",
       "      <td>EX_csn_e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Cytosine exchange</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_5mtr_e</th>\n",
       "      <td>EX_5mtr_e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>5-Methylthio-D-ribose exchange</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_dtmp_e</th>\n",
       "      <td>EX_dtmp_e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>DTMP exchange</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_6pgc_e</th>\n",
       "      <td>EX_6pgc_e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>6 Phospho D gluconate exchange</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_ctbt_e</th>\n",
       "      <td>EX_ctbt_e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Crotonobetaine exchange</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_cu2_e</th>\n",
       "      <td>EX_cu2_e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Cu2+ exchange</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_Larab_e</th>\n",
       "      <td>EX_Larab_e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Alpha L Arabinan exchange</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_ectoine_e</th>\n",
       "      <td>EX_ectoine_e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Ectoine exchange</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_cys__D_e</th>\n",
       "      <td>EX_cys__D_e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>D-Cysteine exchange</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_cys__L_e</th>\n",
       "      <td>EX_cys__L_e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>L-Cysteine exchange</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_eths_e</th>\n",
       "      <td>EX_eths_e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Ethanesulfonate exchange</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_cyst__L_e</th>\n",
       "      <td>EX_cyst__L_e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>L Cystine exchange</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_Lcyst_e</th>\n",
       "      <td>EX_Lcyst_e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>L-Cysteate exchange</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  reaction  lower_bound  upper_bound  is_reversible  \\\n",
       "EX_etha_e        EX_etha_e          0.0     999999.0          False   \n",
       "EX_drib_e        EX_drib_e          0.0     999999.0          False   \n",
       "EX_csn_e          EX_csn_e          0.0     999999.0          False   \n",
       "EX_5mtr_e        EX_5mtr_e          0.0     999999.0          False   \n",
       "EX_dtmp_e        EX_dtmp_e          0.0     999999.0          False   \n",
       "EX_6pgc_e        EX_6pgc_e          0.0     999999.0          False   \n",
       "EX_ctbt_e        EX_ctbt_e          0.0     999999.0          False   \n",
       "EX_cu2_e          EX_cu2_e          0.0     999999.0          False   \n",
       "EX_Larab_e      EX_Larab_e          0.0     999999.0          False   \n",
       "EX_ectoine_e  EX_ectoine_e          0.0     999999.0          False   \n",
       "EX_cys__D_e    EX_cys__D_e          0.0     999999.0          False   \n",
       "EX_cys__L_e    EX_cys__L_e          0.0     999999.0          False   \n",
       "EX_eths_e        EX_eths_e          0.0     999999.0          False   \n",
       "EX_cyst__L_e  EX_cyst__L_e          0.0     999999.0          False   \n",
       "EX_Lcyst_e      EX_Lcyst_e          0.0     999999.0          False   \n",
       "\n",
       "                                        name  flux  \n",
       "EX_etha_e              Ethanolamine exchange   0.0  \n",
       "EX_drib_e            Deoxy D Ribose exchange   0.0  \n",
       "EX_csn_e                   Cytosine exchange   0.0  \n",
       "EX_5mtr_e     5-Methylthio-D-ribose exchange   0.0  \n",
       "EX_dtmp_e                      DTMP exchange   0.0  \n",
       "EX_6pgc_e     6 Phospho D gluconate exchange   0.0  \n",
       "EX_ctbt_e            Crotonobetaine exchange   0.0  \n",
       "EX_cu2_e                       Cu2+ exchange   0.0  \n",
       "EX_Larab_e         Alpha L Arabinan exchange   0.0  \n",
       "EX_ectoine_e                Ectoine exchange   0.0  \n",
       "EX_cys__D_e              D-Cysteine exchange   0.0  \n",
       "EX_cys__L_e              L-Cysteine exchange   0.0  \n",
       "EX_eths_e           Ethanesulfonate exchange   0.0  \n",
       "EX_cyst__L_e              L Cystine exchange   0.0  \n",
       "EX_Lcyst_e               L-Cysteate exchange   0.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds_df = pd.DataFrame({\n",
    "    'reaction': [r.id for r in model.reactions],\n",
    "    'lower_bound': [r.lower_bound for r in model.reactions],\n",
    "    'upper_bound': [r.upper_bound for r in model.reactions],\n",
    "    'is_reversible': [reaction.lower_bound < 0 and reaction.upper_bound > 0 for reaction in model.reactions],\n",
    "    'name': [r.name for r in model.reactions],    \n",
    "    'flux': v\n",
    "})\n",
    "bounds_df.head(30)\n",
    "\n",
    "# Merge with bounds_df to add essentiality labels\n",
    "#bounds_df = bounds_df.merge(reaction_essentials_df, on=\"reaction\", how=\"left\")\n",
    "# Show the updated dataset\n",
    "#bounds_df.to_csv('bounds.csv')\n",
    "bounds_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35508463-059c-4c30-a133-0973de690ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_flux_reactions_df =  bounds_df[bounds_df[\"flux\"].abs() > 1e-10]\n",
    "low_flux_reactions = bounds_df[bounds_df[\"flux\"].abs()> 1e-10][\"reaction\"].tolist()\n",
    "\n",
    "# Get indices of selected reactions in the stoichiometric matrix\n",
    "reaction_indices = [i for i, r in enumerate(bounds_df[\"reaction\"]) if r in low_flux_reactions]\n",
    "\n",
    "# Reduce S by selecting only the columns corresponding to low-flux reactions\n",
    "S_reduced = S[:, reaction_indices]\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "S_reduced_df = pd.DataFrame(S_reduced, columns=low_flux_reactions)\n",
    "\n",
    "# Display the reduced stoichiometric matrix\n",
    "#S_reduced_df.head()\n",
    "flux_array = low_flux_reactions_df['flux'].to_numpy()  # or df['flux'].values for older pandas versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "746607d4-db31-4716-b799-94bb9122e2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 362 essential genes\n",
      "Found 60 essential reactions, 151 non-essential reactions\n",
      "123 reactions marked as unknown\n"
     ]
    }
   ],
   "source": [
    "def assign_reaction_essentiality(model, essential_genes_df, low_flux_reactions=None):\n",
    "    # Extract gene IDs from the DataFrame\n",
    "    essential_genes_set = set()\n",
    "    for gene_set in essential_genes_df['ids']:\n",
    "        for gene_id in gene_set:\n",
    "            essential_genes_set.add(gene_id)\n",
    "    \n",
    "    print(f\"Processing {len(essential_genes_set)} essential genes\")\n",
    "    \n",
    "    # If no low_flux_reactions specified, use all reactions\n",
    "    if low_flux_reactions is None:\n",
    "        low_flux_reactions = [r.id for r in model.reactions]\n",
    "    \n",
    "    # Dictionary to store essentiality results\n",
    "    rxn_essentiality = {}\n",
    "    essential_rxn_count = 0\n",
    "    non_essential_rxn_count = 0\n",
    "    \n",
    "    # Process each reaction\n",
    "    for rxn_id in low_flux_reactions:\n",
    "        # Get the reaction object\n",
    "        rxn = model.reactions.get_by_id(rxn_id)\n",
    "        \n",
    "        # Skip reactions without genes (spontaneous or exchange reactions)\n",
    "        if not rxn.genes:\n",
    "            rxn_essentiality[rxn.id] =-1\n",
    "           \n",
    "            continue\n",
    "        \n",
    "         # ONE-TO-ONE // ONE-TO-MANY\n",
    "        if len(rxn.genes) == 1:\n",
    "            gene = list(rxn.genes)[0]\n",
    "            if gene.id in essential_genes_set:\n",
    "                rxn_essentiality[rxn.id] = 1\n",
    "                essential_rxn_count += 1\n",
    "            \n",
    "            else:\n",
    "                rxn_essentiality[rxn.id] = 0\n",
    "                non_essential_rxn_count += 1\n",
    "            \n",
    "        else:\n",
    "            '''\n",
    "            # If multiple genes, check if at least one is essential\n",
    "            essential_gene_found = any(gene.id in essential_genes_set for gene in rxn.genes)\n",
    "\n",
    "            if essential_gene_found:\n",
    "                rxn_essentiality[rxn.id] = 1  \n",
    "                essential_rxn_count += 1\n",
    "            else: \n",
    "                rxn_essentiality[rxn.id] = 0  # None of the genes are essential → Non-essential\n",
    "                non_essential_rxn_count += 1\n",
    "            '''\n",
    "            rxn_essentiality[rxn.id] =-1  \n",
    "                           \n",
    "    print(f\"Found {essential_rxn_count} essential reactions, {non_essential_rxn_count} non-essential reactions\")\n",
    "    print(f\"{len(low_flux_reactions) - essential_rxn_count - non_essential_rxn_count} reactions marked as unknown\")\n",
    "    \n",
    "    return rxn_essentiality\n",
    "\n",
    "low_flux_essentials = assign_reaction_essentiality(model, essentials_df, low_flux_reactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fcef0d2a-f3d5-4735-9e41-e0dd3e2a5525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I_m shape: (334, 334)\n",
      "Zeros shape: (334, 334)\n",
      "diag_r shape: (334, 334)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outflow_EX_ca2_e_forward</th>\n",
       "      <th>outflow_EX_ca2_e_reverse</th>\n",
       "      <th>outflow_EX_so4_e_forward</th>\n",
       "      <th>outflow_EX_so4_e_reverse</th>\n",
       "      <th>outflow_EX_co2_e_forward</th>\n",
       "      <th>outflow_EX_h2o_e_forward</th>\n",
       "      <th>outflow_EX_h2o_e_reverse</th>\n",
       "      <th>outflow_EX_h_e_forward</th>\n",
       "      <th>outflow_EX_h_e_reverse</th>\n",
       "      <th>outflow_2S6HCCi_forward</th>\n",
       "      <th>...</th>\n",
       "      <th>inflow_KAS4_reverse</th>\n",
       "      <th>inflow_KAS6_forward</th>\n",
       "      <th>inflow_KAS6_reverse</th>\n",
       "      <th>inflow_KAS11_forward</th>\n",
       "      <th>inflow_KAS11_reverse</th>\n",
       "      <th>inflow_PGMT_forward</th>\n",
       "      <th>inflow_RNDR3_forward</th>\n",
       "      <th>inflow_TECA3S45_reverse</th>\n",
       "      <th>inflow_PGM_reverse</th>\n",
       "      <th>inflow_PHCYT_BS_forward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EX_ca2_e_forward</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_ca2_e_reverse</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_so4_e_forward</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_so4_e_reverse</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_co2_e_forward</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PGMT_forward</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RNDR3_forward</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TECA3S45_reverse</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PGM_reverse</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHCYT_BS_forward</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.367112</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>332 rows × 664 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  outflow_EX_ca2_e_forward  outflow_EX_ca2_e_reverse  \\\n",
       "EX_ca2_e_forward                       0.0                       0.0   \n",
       "EX_ca2_e_reverse                       0.0                       0.0   \n",
       "EX_so4_e_forward                       0.0                       0.0   \n",
       "EX_so4_e_reverse                       0.0                       0.0   \n",
       "EX_co2_e_forward                       0.0                       0.0   \n",
       "...                                    ...                       ...   \n",
       "PGMT_forward                           0.0                       0.0   \n",
       "RNDR3_forward                          0.0                       0.0   \n",
       "TECA3S45_reverse                       0.0                       0.0   \n",
       "PGM_reverse                            0.0                       0.0   \n",
       "PHCYT_BS_forward                       0.0                       0.0   \n",
       "\n",
       "                  outflow_EX_so4_e_forward  outflow_EX_so4_e_reverse  \\\n",
       "EX_ca2_e_forward                       0.0                       0.0   \n",
       "EX_ca2_e_reverse                       0.0                       0.0   \n",
       "EX_so4_e_forward                       0.0                       0.0   \n",
       "EX_so4_e_reverse                       0.0                       0.0   \n",
       "EX_co2_e_forward                       0.0                       0.0   \n",
       "...                                    ...                       ...   \n",
       "PGMT_forward                           0.0                       0.0   \n",
       "RNDR3_forward                          0.0                       0.0   \n",
       "TECA3S45_reverse                       0.0                       0.0   \n",
       "PGM_reverse                            0.0                       0.0   \n",
       "PHCYT_BS_forward                       0.0                       0.0   \n",
       "\n",
       "                  outflow_EX_co2_e_forward  outflow_EX_h2o_e_forward  \\\n",
       "EX_ca2_e_forward                       0.0                       0.0   \n",
       "EX_ca2_e_reverse                       0.0                       0.0   \n",
       "EX_so4_e_forward                       0.0                       0.0   \n",
       "EX_so4_e_reverse                       0.0                       0.0   \n",
       "EX_co2_e_forward                       0.0                       0.0   \n",
       "...                                    ...                       ...   \n",
       "PGMT_forward                           0.0                       0.0   \n",
       "RNDR3_forward                          0.0                       0.0   \n",
       "TECA3S45_reverse                       0.0                       0.0   \n",
       "PGM_reverse                            0.0                       0.0   \n",
       "PHCYT_BS_forward                       0.0                       0.0   \n",
       "\n",
       "                  outflow_EX_h2o_e_reverse  outflow_EX_h_e_forward  \\\n",
       "EX_ca2_e_forward                       0.0                     0.0   \n",
       "EX_ca2_e_reverse                       0.0                     0.0   \n",
       "EX_so4_e_forward                       0.0                     0.0   \n",
       "EX_so4_e_reverse                       0.0                     0.0   \n",
       "EX_co2_e_forward                       0.0                     0.0   \n",
       "...                                    ...                     ...   \n",
       "PGMT_forward                           0.0                     0.0   \n",
       "RNDR3_forward                          0.0                     0.0   \n",
       "TECA3S45_reverse                       0.0                     0.0   \n",
       "PGM_reverse                            0.0                     0.0   \n",
       "PHCYT_BS_forward                       0.0                     0.0   \n",
       "\n",
       "                  outflow_EX_h_e_reverse  outflow_2S6HCCi_forward  ...  \\\n",
       "EX_ca2_e_forward                     0.0                      0.0  ...   \n",
       "EX_ca2_e_reverse                     0.0                      0.0  ...   \n",
       "EX_so4_e_forward                     0.0                      0.0  ...   \n",
       "EX_so4_e_reverse                     0.0                      0.0  ...   \n",
       "EX_co2_e_forward                     0.0                      0.0  ...   \n",
       "...                                  ...                      ...  ...   \n",
       "PGMT_forward                         0.0                      0.0  ...   \n",
       "RNDR3_forward                        0.0                      0.0  ...   \n",
       "TECA3S45_reverse                     0.0                      0.0  ...   \n",
       "PGM_reverse                          0.0                      0.0  ...   \n",
       "PHCYT_BS_forward                     0.0                      0.0  ...   \n",
       "\n",
       "                  inflow_KAS4_reverse  inflow_KAS6_forward  \\\n",
       "EX_ca2_e_forward             0.000000             0.000000   \n",
       "EX_ca2_e_reverse             0.000000             0.000000   \n",
       "EX_so4_e_forward             0.000000             0.000000   \n",
       "EX_so4_e_reverse             0.000000             0.000000   \n",
       "EX_co2_e_forward             0.001449             0.001449   \n",
       "...                               ...                  ...   \n",
       "PGMT_forward                 0.000000             0.000000   \n",
       "RNDR3_forward                0.000000             0.000000   \n",
       "TECA3S45_reverse             0.000000             0.000000   \n",
       "PGM_reverse                  0.000000             0.000000   \n",
       "PHCYT_BS_forward             0.000000             0.000000   \n",
       "\n",
       "                  inflow_KAS6_reverse  inflow_KAS11_forward  \\\n",
       "EX_ca2_e_forward             0.000000              0.000000   \n",
       "EX_ca2_e_reverse             0.000000              0.000000   \n",
       "EX_so4_e_forward             0.000000              0.000000   \n",
       "EX_so4_e_reverse             0.000000              0.000000   \n",
       "EX_co2_e_forward             0.001449              0.001734   \n",
       "...                               ...                   ...   \n",
       "PGMT_forward                 0.000000              0.000000   \n",
       "RNDR3_forward                0.000000              0.000000   \n",
       "TECA3S45_reverse             0.000000              0.000000   \n",
       "PGM_reverse                  0.000000              0.000000   \n",
       "PHCYT_BS_forward             0.000000              0.000000   \n",
       "\n",
       "                  inflow_KAS11_reverse  inflow_PGMT_forward  \\\n",
       "EX_ca2_e_forward              0.000000                  0.0   \n",
       "EX_ca2_e_reverse              0.000000                  0.0   \n",
       "EX_so4_e_forward              0.000000                  0.0   \n",
       "EX_so4_e_reverse              0.000000                  0.0   \n",
       "EX_co2_e_forward              0.001864                  0.0   \n",
       "...                                ...                  ...   \n",
       "PGMT_forward                  0.000000                  0.0   \n",
       "RNDR3_forward                 0.000000                  0.0   \n",
       "TECA3S45_reverse              0.000000                  0.0   \n",
       "PGM_reverse                   0.000000                  0.0   \n",
       "PHCYT_BS_forward              0.000000                  0.0   \n",
       "\n",
       "                  inflow_RNDR3_forward  inflow_TECA3S45_reverse  \\\n",
       "EX_ca2_e_forward                   0.0                      0.0   \n",
       "EX_ca2_e_reverse                   0.0                      0.0   \n",
       "EX_so4_e_forward                   0.0                      0.0   \n",
       "EX_so4_e_reverse                   0.0                      0.0   \n",
       "EX_co2_e_forward                   0.0                      0.0   \n",
       "...                                ...                      ...   \n",
       "PGMT_forward                       0.0                      0.0   \n",
       "RNDR3_forward                      0.0                      0.0   \n",
       "TECA3S45_reverse                   0.0                      0.0   \n",
       "PGM_reverse                        0.0                      0.0   \n",
       "PHCYT_BS_forward                   0.0                      0.0   \n",
       "\n",
       "                  inflow_PGM_reverse  inflow_PHCYT_BS_forward  \n",
       "EX_ca2_e_forward            0.000000                      0.0  \n",
       "EX_ca2_e_reverse            0.000000                      0.0  \n",
       "EX_so4_e_forward            0.000000                      0.0  \n",
       "EX_so4_e_reverse            0.000000                      0.0  \n",
       "EX_co2_e_forward            0.000000                      0.0  \n",
       "...                              ...                      ...  \n",
       "PGMT_forward                0.000000                      0.0  \n",
       "RNDR3_forward               0.000000                      0.0  \n",
       "TECA3S45_reverse            0.000000                      0.0  \n",
       "PGM_reverse                 0.000000                      0.0  \n",
       "PHCYT_BS_forward           15.367112                      0.0  \n",
       "\n",
       "[332 rows x 664 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_mfg_with_labels(S_df, fba_solution):\n",
    "    # Extract the stoichiometric matrix and reaction labels\n",
    "    reaction_labels = S_df.columns.tolist()\n",
    "    metabolite_labels = S_df.index.tolist()\n",
    "    S = S_df.values\n",
    "    \n",
    "    # Get dimensions\n",
    "    n_metabolites, n_reactions = S.shape\n",
    "    \n",
    "    # Unfold the FBA solution into forward and reverse reactions\n",
    "    v_star = np.array(fba_solution)\n",
    "    v_star_2m = np.concatenate([\n",
    "        0.5 * (np.abs(v_star) + v_star),\n",
    "        0.5 * (np.abs(v_star) - v_star)\n",
    "    ])\n",
    "    \n",
    "    # Create label list for unfolded reactions\n",
    "    unfolded_labels = []\n",
    "    for label in reaction_labels:\n",
    "        unfolded_labels.append(f\"{label}_forward\")\n",
    "        unfolded_labels.append(f\"{label}_reverse\")\n",
    "    \n",
    "    # Construct the unfolded stoichiometric matrix\n",
    "    I_m = np.eye(n_reactions)\n",
    "    \n",
    "    r = np.ones(n_reactions)  \n",
    "    #r = np.array([1 if r.lower_bound < 0 else 0 for r in model.reactions])\n",
    "    r = np.array(low_flux_reactions_df['is_reversible'].astype(int)) \n",
    "    diag_r = np.diag(r)\n",
    "    print(f\"I_m shape: {I_m.shape}\")\n",
    "    print(f\"Zeros shape: {np.zeros((n_reactions, n_reactions)).shape}\")\n",
    "    print(f\"diag_r shape: {diag_r.shape}\")\n",
    "    block_matrix = np.block([\n",
    "        [I_m, np.zeros((n_reactions, n_reactions))],\n",
    "        [np.zeros((n_reactions, n_reactions)), diag_r]\n",
    "    ])\n",
    "    \n",
    "    S_2m = np.dot(np.hstack([S, -S]), block_matrix)\n",
    "    \n",
    "    # Calculate production and consumption matrices\n",
    "    S_plus_2m = 0.5 * (np.abs(S_2m) + S_2m)\n",
    "    S_minus_2m = 0.5 * (np.abs(S_2m) - S_2m)\n",
    "    \n",
    "    # Calculate the diagonal matrix of fluxes\n",
    "    V_star = np.diag(v_star_2m)\n",
    "    \n",
    "    # Calculate the flux of each metabolite\n",
    "    j_v_star = np.dot(S_plus_2m, v_star_2m)\n",
    "    \n",
    "    # Create a diagonal matrix for the inverse of j_v_star\n",
    "    j_v_star_safe = np.where(j_v_star != 0, j_v_star, 1.0)  # Replace zeros with 1\n",
    "    J_v_star = np.diag(1.0 / j_v_star_safe)\n",
    "    \n",
    "    # Calculate the MFG adjacency matrix\n",
    "    S_plus_2m_V = np.dot(S_plus_2m, V_star)\n",
    "    S_minus_2m_V = np.dot(S_minus_2m, V_star)\n",
    "    \n",
    "    M_v_star = np.dot(np.dot(S_plus_2m_V.T, J_v_star), S_minus_2m_V)\n",
    "    \n",
    "    # Create a DataFrame to maintain the labels\n",
    "    mfg_df = pd.DataFrame(M_v_star, index=unfolded_labels, columns=unfolded_labels)\n",
    "    \n",
    "    # Identify the connected component\n",
    "    # A node is connected if it has at least one non-zero entry in its row or column\n",
    "    connected_mask = ((np.abs(M_v_star).sum(axis=0) > 1e-10) | (np.abs(M_v_star).sum(axis=1) > 1e-10))\n",
    "    connected_indices = np.where(connected_mask)[0]\n",
    "    \n",
    "    # Check if there are any connected nodes\n",
    "    if len(connected_indices) == 0:\n",
    "        return {\n",
    "            'full_mfg': mfg_df,\n",
    "            'connected_mfg': pd.DataFrame(),\n",
    "            'connected_labels': [],\n",
    "            'original_connected_labels': []\n",
    "        }\n",
    "    \n",
    "    # Extract the connected component subgraph with labels\n",
    "    connected_labels = [unfolded_labels[i] for i in connected_indices]\n",
    "    M_k = M_v_star[connected_indices, :][:, connected_indices]\n",
    "    mfg_connected_df = pd.DataFrame(M_k, index=connected_labels, columns=connected_labels)\n",
    "    \n",
    "    # Map the connected reactions back to original reaction labels\n",
    "    # Remove the \"_forward\" and \"_reverse\" suffixes\n",
    "    original_connected_labels = []\n",
    "    for label in connected_labels:\n",
    "        if label.endswith(\"_forward\"):\n",
    "            original_connected_labels.append(label[:-8])\n",
    "        elif label.endswith(\"_reverse\"):\n",
    "            original_connected_labels.append(label[:-8])\n",
    "    \n",
    "    # Remove duplicates to get unique reactions in the connected component\n",
    "    original_connected_labels = list(set(original_connected_labels))\n",
    "    \n",
    "    return {\n",
    "        'full_mfg': mfg_df,\n",
    "        'connected_mfg': mfg_connected_df,\n",
    "        'connected_labels': connected_labels,\n",
    "        'original_connected_labels': original_connected_labels\n",
    "    }\n",
    "\n",
    "def extract_features(mfg_connected_df):\n",
    "    M_k = mfg_connected_df.values\n",
    "    M_k_transpose = M_k.T\n",
    "    \n",
    "    # Create feature matrix X = [M_k M_k']\n",
    "    X = np.hstack([M_k, M_k_transpose])\n",
    "    \n",
    "    # Normalize features to unit variance (without centering)\n",
    "    std = np.std(X, axis=0, keepdims=True)\n",
    "    std[std == 0] = 1.0  # Avoid division by zero\n",
    "    X_normalized = X / std\n",
    "    \n",
    "    # Create DataFrame with labels\n",
    "    X_df = pd.DataFrame(\n",
    "        X_normalized, \n",
    "        index=mfg_connected_df.index,\n",
    "        columns=[f\"outflow_{col}\" for col in mfg_connected_df.columns] + \n",
    "                [f\"inflow_{col}\" for col in mfg_connected_df.columns]\n",
    "    )\n",
    "    \n",
    "    return X_df\n",
    "\n",
    "mfg_result = compute_mfg_with_labels(S_reduced_df, flux_array)\n",
    "\n",
    "# The connected component of the MFG with labels\n",
    "connected_mfg = mfg_result['connected_mfg']\n",
    "X_features = extract_features(connected_mfg)\n",
    "X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "92cc4d7e-1cd8-424d-834d-cc0831a68f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_essentiality_to_connected_mfg(mfg_result, essentiality_dict):\n",
    "    connected_labels = mfg_result['connected_labels']\n",
    "    essentiality_mapped = {}\n",
    "    \n",
    "    # First, create a map of base reactions to their essentiality\n",
    "    base_reaction_essentiality = {}\n",
    "    for label in connected_labels:\n",
    "        if label.endswith(\"_forward\"):\n",
    "            # Extract original reaction name\n",
    "            original_label = label[:-8]  # Remove \"_forward\" suffix\n",
    "            if original_label in essentiality_dict:\n",
    "                base_reaction_essentiality[original_label] = essentiality_dict[original_label]\n",
    "    \n",
    "    # Now map both forward and reverse reactions\n",
    "    for label in connected_labels:\n",
    "        if label.endswith(\"_forward\"):\n",
    "            original_label = label[:-8]\n",
    "            essentiality_mapped[label] = base_reaction_essentiality.get(original_label, -1)\n",
    "        elif label.endswith(\"_reverse\"):\n",
    "            original_label = label[:-8]\n",
    "            essentiality_mapped[label] = base_reaction_essentiality.get(original_label, -1)\n",
    "    \n",
    "    return essentiality_mapped\n",
    "\n",
    "# Then you can use this function with your feature extraction\n",
    "def extract_features_with_labels(mfg_connected_df, essentiality_mapped):\n",
    "    M_k = mfg_connected_df.values\n",
    "    M_k_transpose = M_k.T\n",
    "    \n",
    "    # Create feature matrix X = [M_k M_k']\n",
    "    X = np.hstack([M_k, M_k_transpose])\n",
    "    \n",
    "    # Normalize features to unit variance (without centering)\n",
    "    std = np.std(X, axis=0, keepdims=True)\n",
    "    std[std == 0] = 1.0  # Avoid division by zero\n",
    "    X_normalized = X / std\n",
    "    \n",
    "    # Create DataFrame with features\n",
    "    X_df = pd.DataFrame(\n",
    "        X_normalized, \n",
    "        index=mfg_connected_df.index,\n",
    "        columns=[f\"outflow_{col}\" for col in mfg_connected_df.columns] + \n",
    "                [f\"inflow_{col}\" for col in mfg_connected_df.columns]\n",
    "    )\n",
    "    \n",
    "    # Add essentiality labels\n",
    "    X_df['essentiality'] = X_df.index.map(lambda x: essentiality_mapped.get(x, -1))\n",
    "    \n",
    "    return X_df\n",
    "\n",
    "essentiality_mapped = map_essentiality_to_connected_mfg(mfg_result, low_flux_essentials)\n",
    "\n",
    "# Extract features and add essentiality labels\n",
    "X_with_labels = extract_features_with_labels(mfg_result['connected_mfg'], essentiality_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "77fd9187-34b8-4bde-84ee-cc81573a1ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outflow_EX_ca2_e_forward</th>\n",
       "      <th>outflow_EX_ca2_e_reverse</th>\n",
       "      <th>outflow_EX_so4_e_forward</th>\n",
       "      <th>outflow_EX_so4_e_reverse</th>\n",
       "      <th>outflow_EX_co2_e_forward</th>\n",
       "      <th>outflow_EX_h2o_e_forward</th>\n",
       "      <th>outflow_EX_h2o_e_reverse</th>\n",
       "      <th>outflow_EX_h_e_forward</th>\n",
       "      <th>outflow_EX_h_e_reverse</th>\n",
       "      <th>outflow_2S6HCCi_forward</th>\n",
       "      <th>...</th>\n",
       "      <th>inflow_KAS6_forward</th>\n",
       "      <th>inflow_KAS6_reverse</th>\n",
       "      <th>inflow_KAS11_forward</th>\n",
       "      <th>inflow_KAS11_reverse</th>\n",
       "      <th>inflow_PGMT_forward</th>\n",
       "      <th>inflow_RNDR3_forward</th>\n",
       "      <th>inflow_TECA3S45_reverse</th>\n",
       "      <th>inflow_PGM_reverse</th>\n",
       "      <th>inflow_PHCYT_BS_forward</th>\n",
       "      <th>essentiality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EX_ca2_e_forward</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_ca2_e_reverse</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_so4_e_forward</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_so4_e_reverse</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX_co2_e_forward</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PGMT_forward</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RNDR3_forward</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TECA3S45_reverse</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PGM_reverse</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHCYT_BS_forward</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.367112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>332 rows × 665 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  outflow_EX_ca2_e_forward  outflow_EX_ca2_e_reverse  \\\n",
       "EX_ca2_e_forward                       0.0                       0.0   \n",
       "EX_ca2_e_reverse                       0.0                       0.0   \n",
       "EX_so4_e_forward                       0.0                       0.0   \n",
       "EX_so4_e_reverse                       0.0                       0.0   \n",
       "EX_co2_e_forward                       0.0                       0.0   \n",
       "...                                    ...                       ...   \n",
       "PGMT_forward                           0.0                       0.0   \n",
       "RNDR3_forward                          0.0                       0.0   \n",
       "TECA3S45_reverse                       0.0                       0.0   \n",
       "PGM_reverse                            0.0                       0.0   \n",
       "PHCYT_BS_forward                       0.0                       0.0   \n",
       "\n",
       "                  outflow_EX_so4_e_forward  outflow_EX_so4_e_reverse  \\\n",
       "EX_ca2_e_forward                       0.0                       0.0   \n",
       "EX_ca2_e_reverse                       0.0                       0.0   \n",
       "EX_so4_e_forward                       0.0                       0.0   \n",
       "EX_so4_e_reverse                       0.0                       0.0   \n",
       "EX_co2_e_forward                       0.0                       0.0   \n",
       "...                                    ...                       ...   \n",
       "PGMT_forward                           0.0                       0.0   \n",
       "RNDR3_forward                          0.0                       0.0   \n",
       "TECA3S45_reverse                       0.0                       0.0   \n",
       "PGM_reverse                            0.0                       0.0   \n",
       "PHCYT_BS_forward                       0.0                       0.0   \n",
       "\n",
       "                  outflow_EX_co2_e_forward  outflow_EX_h2o_e_forward  \\\n",
       "EX_ca2_e_forward                       0.0                       0.0   \n",
       "EX_ca2_e_reverse                       0.0                       0.0   \n",
       "EX_so4_e_forward                       0.0                       0.0   \n",
       "EX_so4_e_reverse                       0.0                       0.0   \n",
       "EX_co2_e_forward                       0.0                       0.0   \n",
       "...                                    ...                       ...   \n",
       "PGMT_forward                           0.0                       0.0   \n",
       "RNDR3_forward                          0.0                       0.0   \n",
       "TECA3S45_reverse                       0.0                       0.0   \n",
       "PGM_reverse                            0.0                       0.0   \n",
       "PHCYT_BS_forward                       0.0                       0.0   \n",
       "\n",
       "                  outflow_EX_h2o_e_reverse  outflow_EX_h_e_forward  \\\n",
       "EX_ca2_e_forward                       0.0                     0.0   \n",
       "EX_ca2_e_reverse                       0.0                     0.0   \n",
       "EX_so4_e_forward                       0.0                     0.0   \n",
       "EX_so4_e_reverse                       0.0                     0.0   \n",
       "EX_co2_e_forward                       0.0                     0.0   \n",
       "...                                    ...                     ...   \n",
       "PGMT_forward                           0.0                     0.0   \n",
       "RNDR3_forward                          0.0                     0.0   \n",
       "TECA3S45_reverse                       0.0                     0.0   \n",
       "PGM_reverse                            0.0                     0.0   \n",
       "PHCYT_BS_forward                       0.0                     0.0   \n",
       "\n",
       "                  outflow_EX_h_e_reverse  outflow_2S6HCCi_forward  ...  \\\n",
       "EX_ca2_e_forward                     0.0                      0.0  ...   \n",
       "EX_ca2_e_reverse                     0.0                      0.0  ...   \n",
       "EX_so4_e_forward                     0.0                      0.0  ...   \n",
       "EX_so4_e_reverse                     0.0                      0.0  ...   \n",
       "EX_co2_e_forward                     0.0                      0.0  ...   \n",
       "...                                  ...                      ...  ...   \n",
       "PGMT_forward                         0.0                      0.0  ...   \n",
       "RNDR3_forward                        0.0                      0.0  ...   \n",
       "TECA3S45_reverse                     0.0                      0.0  ...   \n",
       "PGM_reverse                          0.0                      0.0  ...   \n",
       "PHCYT_BS_forward                     0.0                      0.0  ...   \n",
       "\n",
       "                  inflow_KAS6_forward  inflow_KAS6_reverse  \\\n",
       "EX_ca2_e_forward             0.000000             0.000000   \n",
       "EX_ca2_e_reverse             0.000000             0.000000   \n",
       "EX_so4_e_forward             0.000000             0.000000   \n",
       "EX_so4_e_reverse             0.000000             0.000000   \n",
       "EX_co2_e_forward             0.001449             0.001449   \n",
       "...                               ...                  ...   \n",
       "PGMT_forward                 0.000000             0.000000   \n",
       "RNDR3_forward                0.000000             0.000000   \n",
       "TECA3S45_reverse             0.000000             0.000000   \n",
       "PGM_reverse                  0.000000             0.000000   \n",
       "PHCYT_BS_forward             0.000000             0.000000   \n",
       "\n",
       "                  inflow_KAS11_forward  inflow_KAS11_reverse  \\\n",
       "EX_ca2_e_forward              0.000000              0.000000   \n",
       "EX_ca2_e_reverse              0.000000              0.000000   \n",
       "EX_so4_e_forward              0.000000              0.000000   \n",
       "EX_so4_e_reverse              0.000000              0.000000   \n",
       "EX_co2_e_forward              0.001734              0.001864   \n",
       "...                                ...                   ...   \n",
       "PGMT_forward                  0.000000              0.000000   \n",
       "RNDR3_forward                 0.000000              0.000000   \n",
       "TECA3S45_reverse              0.000000              0.000000   \n",
       "PGM_reverse                   0.000000              0.000000   \n",
       "PHCYT_BS_forward              0.000000              0.000000   \n",
       "\n",
       "                  inflow_PGMT_forward  inflow_RNDR3_forward  \\\n",
       "EX_ca2_e_forward                  0.0                   0.0   \n",
       "EX_ca2_e_reverse                  0.0                   0.0   \n",
       "EX_so4_e_forward                  0.0                   0.0   \n",
       "EX_so4_e_reverse                  0.0                   0.0   \n",
       "EX_co2_e_forward                  0.0                   0.0   \n",
       "...                               ...                   ...   \n",
       "PGMT_forward                      0.0                   0.0   \n",
       "RNDR3_forward                     0.0                   0.0   \n",
       "TECA3S45_reverse                  0.0                   0.0   \n",
       "PGM_reverse                       0.0                   0.0   \n",
       "PHCYT_BS_forward                  0.0                   0.0   \n",
       "\n",
       "                  inflow_TECA3S45_reverse  inflow_PGM_reverse  \\\n",
       "EX_ca2_e_forward                      0.0            0.000000   \n",
       "EX_ca2_e_reverse                      0.0            0.000000   \n",
       "EX_so4_e_forward                      0.0            0.000000   \n",
       "EX_so4_e_reverse                      0.0            0.000000   \n",
       "EX_co2_e_forward                      0.0            0.000000   \n",
       "...                                   ...                 ...   \n",
       "PGMT_forward                          0.0            0.000000   \n",
       "RNDR3_forward                         0.0            0.000000   \n",
       "TECA3S45_reverse                      0.0            0.000000   \n",
       "PGM_reverse                           0.0            0.000000   \n",
       "PHCYT_BS_forward                      0.0           15.367112   \n",
       "\n",
       "                  inflow_PHCYT_BS_forward  essentiality  \n",
       "EX_ca2_e_forward                      0.0            -1  \n",
       "EX_ca2_e_reverse                      0.0            -1  \n",
       "EX_so4_e_forward                      0.0            -1  \n",
       "EX_so4_e_reverse                      0.0            -1  \n",
       "EX_co2_e_forward                      0.0            -1  \n",
       "...                                   ...           ...  \n",
       "PGMT_forward                          0.0             0  \n",
       "RNDR3_forward                         0.0            -1  \n",
       "TECA3S45_reverse                      0.0            -1  \n",
       "PGM_reverse                           0.0            -1  \n",
       "PHCYT_BS_forward                      0.0             1  \n",
       "\n",
       "[332 rows x 665 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_with_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48860bbf-53d7-4dd6-9ffa-d5ac5fdc2894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameter combination 1/12:\n",
      "{'hidden_features': 8, 'num_heads': 8, 'dropout': 0.3, 'lr': 0.0005, 'weight_decay': 0.0005, 'use_class_weights': False}\n",
      "Training fold 1/5\n",
      "Epoch: 20, Train Loss: 0.6236, Val Loss: 0.5904, Val Acc: 0.7222\n",
      "Epoch: 40, Train Loss: 0.5039, Val Loss: 0.6509, Val Acc: 0.8056\n",
      "Epoch: 60, Train Loss: 0.4865, Val Loss: 0.7138, Val Acc: 0.8056\n",
      "Epoch: 80, Train Loss: 0.4803, Val Loss: 0.5038, Val Acc: 0.8611\n",
      "Epoch: 100, Train Loss: 0.4950, Val Loss: 0.6062, Val Acc: 0.7222\n",
      "Epoch: 120, Train Loss: 0.4675, Val Loss: 0.6087, Val Acc: 0.7778\n",
      "Epoch: 140, Train Loss: 0.4102, Val Loss: 0.5050, Val Acc: 0.7778\n",
      "Training fold 2/5\n",
      "Epoch: 20, Train Loss: 0.5108, Val Loss: 0.6688, Val Acc: 0.6944\n",
      "Epoch: 40, Train Loss: 0.4656, Val Loss: 0.7998, Val Acc: 0.5833\n",
      "Epoch: 60, Train Loss: 0.4001, Val Loss: 0.7317, Val Acc: 0.6389\n",
      "Epoch: 80, Train Loss: 0.3685, Val Loss: 0.6027, Val Acc: 0.7500\n",
      "Epoch: 100, Train Loss: 0.4552, Val Loss: 0.9155, Val Acc: 0.6111\n",
      "Epoch: 120, Train Loss: 0.4016, Val Loss: 0.9085, Val Acc: 0.6667\n",
      "Epoch: 140, Train Loss: 0.3794, Val Loss: 0.8822, Val Acc: 0.6389\n",
      "Training fold 3/5\n",
      "Epoch: 20, Train Loss: 0.7240, Val Loss: 0.7900, Val Acc: 0.5833\n",
      "Epoch: 40, Train Loss: 0.5583, Val Loss: 0.5992, Val Acc: 0.6944\n",
      "Epoch: 60, Train Loss: 0.5192, Val Loss: 0.5269, Val Acc: 0.7222\n",
      "Epoch: 80, Train Loss: 0.4389, Val Loss: 0.6367, Val Acc: 0.7778\n",
      "Epoch: 100, Train Loss: 0.4129, Val Loss: 0.5911, Val Acc: 0.8056\n",
      "Epoch: 120, Train Loss: 0.4513, Val Loss: 0.5789, Val Acc: 0.7778\n",
      "Epoch: 140, Train Loss: 0.4127, Val Loss: 0.7188, Val Acc: 0.6944\n",
      "Training fold 4/5\n",
      "Epoch: 20, Train Loss: 0.5829, Val Loss: 0.8084, Val Acc: 0.6944\n",
      "Epoch: 40, Train Loss: 0.4682, Val Loss: 0.4994, Val Acc: 0.8056\n",
      "Epoch: 60, Train Loss: 0.4162, Val Loss: 0.5545, Val Acc: 0.7500\n",
      "Epoch: 80, Train Loss: 0.4007, Val Loss: 0.5533, Val Acc: 0.7500\n",
      "Epoch: 100, Train Loss: 0.3856, Val Loss: 0.4806, Val Acc: 0.8056\n",
      "Epoch: 120, Train Loss: 0.3973, Val Loss: 0.5556, Val Acc: 0.7500\n",
      "Epoch: 140, Train Loss: 0.3499, Val Loss: 0.6515, Val Acc: 0.7500\n",
      "Training fold 5/5\n",
      "Epoch: 20, Train Loss: 0.4825, Val Loss: 0.7271, Val Acc: 0.7222\n",
      "Epoch: 40, Train Loss: 0.4251, Val Loss: 0.6475, Val Acc: 0.6667\n",
      "Epoch: 60, Train Loss: 0.4065, Val Loss: 0.8683, Val Acc: 0.6944\n",
      "Epoch: 80, Train Loss: 0.3838, Val Loss: 0.6650, Val Acc: 0.7222\n",
      "Epoch: 100, Train Loss: 0.3746, Val Loss: 0.6061, Val Acc: 0.7500\n",
      "Epoch: 120, Train Loss: 0.3660, Val Loss: 0.5976, Val Acc: 0.7500\n",
      "Epoch: 140, Train Loss: 0.3439, Val Loss: 0.7712, Val Acc: 0.7500\n",
      "Average PR-AUC: 0.3743\n",
      "Optimal threshold (balanced accuracy = 0.6222): 0.3259\n",
      "Optimal Threshold - F1: 0.4255, Precision: 0.3846, Recall: 0.4762\n",
      "\n",
      "Fixed Threshold (0.5) Results:\n",
      "Balanced Accuracy: 0.5502\n",
      "F1 Score: 0.2817\n",
      "Precision: 0.3448\n",
      "Recall: 0.2381\n",
      "\n",
      "Hyperparameter combination 2/12:\n",
      "{'hidden_features': 32, 'num_heads': 4, 'dropout': 0.3, 'lr': 0.001, 'weight_decay': 0.0005, 'use_class_weights': True}\n",
      "Training fold 1/5\n",
      "Epoch: 20, Train Loss: 0.8613, Val Loss: 0.5622, Val Acc: 0.6944\n",
      "Epoch: 40, Train Loss: 0.7831, Val Loss: 0.5225, Val Acc: 0.7500\n",
      "Epoch: 60, Train Loss: 0.6063, Val Loss: 0.5582, Val Acc: 0.6944\n",
      "Epoch: 80, Train Loss: 0.5255, Val Loss: 0.6361, Val Acc: 0.6667\n",
      "Epoch: 100, Train Loss: 0.5066, Val Loss: 0.5588, Val Acc: 0.8333\n",
      "Epoch: 120, Train Loss: 0.4773, Val Loss: 0.4851, Val Acc: 0.8056\n",
      "Epoch: 140, Train Loss: 0.3937, Val Loss: 0.4654, Val Acc: 0.8056\n",
      "Training fold 2/5\n",
      "Epoch: 20, Train Loss: 0.9527, Val Loss: 0.6717, Val Acc: 0.7222\n",
      "Epoch: 40, Train Loss: 0.6489, Val Loss: 0.7080, Val Acc: 0.6944\n",
      "Epoch: 60, Train Loss: 0.6921, Val Loss: 1.0076, Val Acc: 0.5000\n",
      "Epoch: 80, Train Loss: 0.6552, Val Loss: 0.7911, Val Acc: 0.6389\n",
      "Epoch: 100, Train Loss: 0.6503, Val Loss: 0.9907, Val Acc: 0.6389\n",
      "Epoch: 120, Train Loss: 0.6355, Val Loss: 0.9985, Val Acc: 0.5556\n",
      "Epoch: 140, Train Loss: 0.6005, Val Loss: 1.1798, Val Acc: 0.6111\n",
      "Training fold 3/5\n",
      "Epoch: 20, Train Loss: 1.5802, Val Loss: 0.8785, Val Acc: 0.5833\n",
      "Epoch: 40, Train Loss: 0.8399, Val Loss: 0.7881, Val Acc: 0.6389\n",
      "Epoch: 60, Train Loss: 0.8137, Val Loss: 0.6923, Val Acc: 0.6111\n",
      "Epoch: 80, Train Loss: 0.7217, Val Loss: 0.7507, Val Acc: 0.6667\n",
      "Epoch: 100, Train Loss: 0.6406, Val Loss: 0.9501, Val Acc: 0.6111\n",
      "Epoch: 120, Train Loss: 0.6231, Val Loss: 0.9305, Val Acc: 0.6667\n",
      "Epoch: 140, Train Loss: 0.5529, Val Loss: 1.0094, Val Acc: 0.5833\n",
      "Training fold 4/5\n",
      "Epoch: 20, Train Loss: 1.1164, Val Loss: 0.8999, Val Acc: 0.5556\n",
      "Epoch: 40, Train Loss: 0.7768, Val Loss: 0.7318, Val Acc: 0.6111\n",
      "Epoch: 60, Train Loss: 0.7607, Val Loss: 0.5295, Val Acc: 0.7222\n",
      "Epoch: 80, Train Loss: 0.8322, Val Loss: 0.7321, Val Acc: 0.6389\n",
      "Epoch: 100, Train Loss: 0.8389, Val Loss: 0.5337, Val Acc: 0.7500\n",
      "Epoch: 120, Train Loss: 0.6862, Val Loss: 0.7003, Val Acc: 0.6667\n",
      "Epoch: 140, Train Loss: 0.5794, Val Loss: 0.8045, Val Acc: 0.6111\n",
      "Training fold 5/5\n",
      "Epoch: 20, Train Loss: 0.8582, Val Loss: 0.9086, Val Acc: 0.5833\n",
      "Epoch: 40, Train Loss: 0.8086, Val Loss: 1.0300, Val Acc: 0.4722\n",
      "Epoch: 60, Train Loss: 0.8814, Val Loss: 0.9364, Val Acc: 0.4722\n",
      "Epoch: 80, Train Loss: 0.7440, Val Loss: 1.1868, Val Acc: 0.5833\n",
      "Epoch: 100, Train Loss: 0.7791, Val Loss: 0.8485, Val Acc: 0.6389\n",
      "Epoch: 120, Train Loss: 0.7457, Val Loss: 0.8193, Val Acc: 0.6111\n",
      "Epoch: 140, Train Loss: 0.7359, Val Loss: 1.1198, Val Acc: 0.6111\n",
      "Average PR-AUC: 0.3823\n",
      "Optimal threshold (balanced accuracy = 0.6568): 0.3871\n",
      "Optimal Threshold - F1: 0.4715, Precision: 0.3580, Recall: 0.6905\n",
      "\n",
      "Fixed Threshold (0.5) Results:\n",
      "Balanced Accuracy: 0.6123\n",
      "F1 Score: 0.4158\n",
      "Precision: 0.3559\n",
      "Recall: 0.5000\n",
      "\n",
      "Hyperparameter combination 3/12:\n",
      "{'hidden_features': 16, 'num_heads': 4, 'dropout': 0.3, 'lr': 0.0005, 'weight_decay': 0.0005, 'use_class_weights': True}\n",
      "Training fold 1/5\n",
      "Epoch: 20, Train Loss: 1.2656, Val Loss: 1.2077, Val Acc: 0.3056\n",
      "Epoch: 40, Train Loss: 0.9695, Val Loss: 0.7420, Val Acc: 0.4444\n",
      "Epoch: 60, Train Loss: 1.1931, Val Loss: 0.5741, Val Acc: 0.6667\n",
      "Epoch: 80, Train Loss: 0.9723, Val Loss: 0.7389, Val Acc: 0.5556\n",
      "Epoch: 100, Train Loss: 0.8111, Val Loss: 0.6893, Val Acc: 0.3889\n",
      "Epoch: 120, Train Loss: 0.7498, Val Loss: 0.8242, Val Acc: 0.7222\n",
      "Epoch: 140, Train Loss: 0.7698, Val Loss: 0.7568, Val Acc: 0.6944\n",
      "Training fold 2/5\n",
      "Epoch: 20, Train Loss: 0.8232, Val Loss: 0.7085, Val Acc: 0.5833\n",
      "Epoch: 40, Train Loss: 0.7771, Val Loss: 0.9117, Val Acc: 0.5556\n",
      "Epoch: 60, Train Loss: 0.7486, Val Loss: 0.8699, Val Acc: 0.5556\n",
      "Epoch: 80, Train Loss: 0.6702, Val Loss: 0.7817, Val Acc: 0.5278\n",
      "Epoch: 100, Train Loss: 0.6078, Val Loss: 0.8949, Val Acc: 0.5000\n",
      "Epoch: 120, Train Loss: 0.6061, Val Loss: 0.8603, Val Acc: 0.5000\n",
      "Epoch: 140, Train Loss: 0.5585, Val Loss: 1.0359, Val Acc: 0.5278\n",
      "Training fold 3/5\n",
      "Epoch: 20, Train Loss: 1.0675, Val Loss: 0.9198, Val Acc: 0.3889\n",
      "Epoch: 40, Train Loss: 0.8965, Val Loss: 0.7277, Val Acc: 0.6944\n",
      "Epoch: 60, Train Loss: 0.8072, Val Loss: 0.6576, Val Acc: 0.6111\n",
      "Epoch: 80, Train Loss: 0.8742, Val Loss: 0.8314, Val Acc: 0.5556\n",
      "Epoch: 100, Train Loss: 0.7493, Val Loss: 0.7431, Val Acc: 0.6389\n",
      "Epoch: 120, Train Loss: 0.7475, Val Loss: 0.7579, Val Acc: 0.6667\n",
      "Epoch: 140, Train Loss: 0.7567, Val Loss: 0.6549, Val Acc: 0.6389\n",
      "Training fold 4/5\n",
      "Epoch: 20, Train Loss: 1.1031, Val Loss: 0.8471, Val Acc: 0.4444\n",
      "Epoch: 40, Train Loss: 0.9865, Val Loss: 0.8449, Val Acc: 0.4444\n",
      "Epoch: 60, Train Loss: 0.8949, Val Loss: 0.8026, Val Acc: 0.5000\n",
      "Epoch: 80, Train Loss: 0.7774, Val Loss: 0.6371, Val Acc: 0.5833\n",
      "Epoch: 100, Train Loss: 0.8187, Val Loss: 0.7405, Val Acc: 0.6944\n",
      "Epoch: 120, Train Loss: 0.7547, Val Loss: 0.7970, Val Acc: 0.5833\n",
      "Epoch: 140, Train Loss: 0.7119, Val Loss: 0.7761, Val Acc: 0.5556\n",
      "Training fold 5/5\n",
      "Epoch: 20, Train Loss: 1.0867, Val Loss: 0.6749, Val Acc: 0.6389\n",
      "Epoch: 40, Train Loss: 0.8945, Val Loss: 0.7124, Val Acc: 0.6389\n",
      "Epoch: 60, Train Loss: 0.7872, Val Loss: 0.7759, Val Acc: 0.5833\n",
      "Epoch: 80, Train Loss: 0.7708, Val Loss: 0.8022, Val Acc: 0.5000\n",
      "Epoch: 100, Train Loss: 0.8686, Val Loss: 0.6547, Val Acc: 0.5833\n",
      "Epoch: 120, Train Loss: 0.8679, Val Loss: 0.7954, Val Acc: 0.6389\n",
      "Epoch: 140, Train Loss: 0.7357, Val Loss: 0.6656, Val Acc: 0.6111\n",
      "Average PR-AUC: 0.3015\n",
      "Optimal threshold (balanced accuracy = 0.5839): 0.5460\n",
      "Optimal Threshold - F1: 0.3750, Precision: 0.3333, Recall: 0.4286\n",
      "\n",
      "Fixed Threshold (0.5) Results:\n",
      "Balanced Accuracy: 0.5621\n",
      "F1 Score: 0.3529\n",
      "Precision: 0.3000\n",
      "Recall: 0.4286\n",
      "\n",
      "Hyperparameter combination 4/12:\n",
      "{'hidden_features': 32, 'num_heads': 4, 'dropout': 0.3, 'lr': 0.0005, 'weight_decay': 0.0001, 'use_class_weights': False}\n",
      "Training fold 1/5\n",
      "Epoch: 20, Train Loss: 0.6355, Val Loss: 0.6687, Val Acc: 0.7222\n",
      "Epoch: 40, Train Loss: 0.4756, Val Loss: 0.5840, Val Acc: 0.7500\n",
      "Epoch: 60, Train Loss: 0.4674, Val Loss: 0.4625, Val Acc: 0.7778\n",
      "Epoch: 80, Train Loss: 0.4783, Val Loss: 0.5446, Val Acc: 0.8056\n",
      "Epoch: 100, Train Loss: 0.3761, Val Loss: 0.6734, Val Acc: 0.7500\n",
      "Epoch: 120, Train Loss: 0.3800, Val Loss: 0.6948, Val Acc: 0.7222\n",
      "Epoch: 140, Train Loss: 0.3528, Val Loss: 0.4883, Val Acc: 0.7778\n",
      "Training fold 2/5\n",
      "Epoch: 20, Train Loss: 0.4978, Val Loss: 0.5874, Val Acc: 0.7222\n",
      "Epoch: 40, Train Loss: 0.3726, Val Loss: 0.6951, Val Acc: 0.6389\n",
      "Epoch: 60, Train Loss: 0.3771, Val Loss: 0.9234, Val Acc: 0.6667\n",
      "Epoch: 80, Train Loss: 0.3716, Val Loss: 0.7919, Val Acc: 0.6111\n",
      "Epoch: 100, Train Loss: 0.3007, Val Loss: 0.8592, Val Acc: 0.6389\n",
      "Epoch: 120, Train Loss: 0.3285, Val Loss: 1.4288, Val Acc: 0.5556\n",
      "Epoch: 140, Train Loss: 0.2772, Val Loss: 1.3484, Val Acc: 0.6389\n",
      "Training fold 3/5\n",
      "Epoch: 20, Train Loss: 0.4920, Val Loss: 0.8071, Val Acc: 0.6389\n",
      "Epoch: 40, Train Loss: 0.4076, Val Loss: 0.7411, Val Acc: 0.6667\n",
      "Epoch: 60, Train Loss: 0.4171, Val Loss: 0.7266, Val Acc: 0.6944\n",
      "Epoch: 80, Train Loss: 0.3653, Val Loss: 0.5869, Val Acc: 0.7222\n",
      "Epoch: 100, Train Loss: 0.3317, Val Loss: 0.7060, Val Acc: 0.6111\n",
      "Epoch: 120, Train Loss: 0.3530, Val Loss: 0.7393, Val Acc: 0.7222\n",
      "Epoch: 140, Train Loss: 0.3487, Val Loss: 0.8080, Val Acc: 0.7222\n",
      "Training fold 4/5\n",
      "Epoch: 20, Train Loss: 0.7797, Val Loss: 0.7077, Val Acc: 0.6111\n",
      "Epoch: 40, Train Loss: 0.5382, Val Loss: 0.5670, Val Acc: 0.8056\n",
      "Epoch: 60, Train Loss: 0.3690, Val Loss: 0.3692, Val Acc: 0.8333\n",
      "Epoch: 80, Train Loss: 0.4611, Val Loss: 0.6006, Val Acc: 0.8333\n",
      "Epoch: 100, Train Loss: 0.4352, Val Loss: 0.4896, Val Acc: 0.8056\n",
      "Epoch: 120, Train Loss: 0.3781, Val Loss: 0.5430, Val Acc: 0.7778\n",
      "Epoch: 140, Train Loss: 0.4326, Val Loss: 0.4648, Val Acc: 0.7778\n",
      "Training fold 5/5\n",
      "Epoch: 20, Train Loss: 0.5661, Val Loss: 0.9843, Val Acc: 0.5833\n",
      "Epoch: 40, Train Loss: 0.5058, Val Loss: 0.7986, Val Acc: 0.6667\n",
      "Epoch: 60, Train Loss: 0.4517, Val Loss: 0.7421, Val Acc: 0.6667\n",
      "Epoch: 80, Train Loss: 0.3997, Val Loss: 0.7065, Val Acc: 0.6667\n",
      "Epoch: 100, Train Loss: 0.4149, Val Loss: 0.7503, Val Acc: 0.7500\n",
      "Epoch: 120, Train Loss: 0.4498, Val Loss: 0.9177, Val Acc: 0.6667\n",
      "Epoch: 140, Train Loss: 0.3705, Val Loss: 0.7155, Val Acc: 0.7222\n",
      "Average PR-AUC: 0.3198\n",
      "Optimal threshold (balanced accuracy = 0.5828): 0.2551\n",
      "Optimal Threshold - F1: 0.3696, Precision: 0.3400, Recall: 0.4048\n",
      "\n",
      "Fixed Threshold (0.5) Results:\n",
      "Balanced Accuracy: 0.5647\n",
      "F1 Score: 0.2985\n",
      "Precision: 0.4000\n",
      "Recall: 0.2381\n",
      "\n",
      "Hyperparameter combination 5/12:\n",
      "{'hidden_features': 16, 'num_heads': 8, 'dropout': 0.5, 'lr': 0.01, 'weight_decay': 0.0005, 'use_class_weights': False}\n",
      "Training fold 1/5\n",
      "Epoch: 20, Train Loss: 1.0979, Val Loss: 1.1122, Val Acc: 0.6944\n",
      "Epoch: 40, Train Loss: 0.7098, Val Loss: 0.9164, Val Acc: 0.7222\n",
      "Epoch: 60, Train Loss: 0.5237, Val Loss: 1.0923, Val Acc: 0.6389\n",
      "Epoch: 80, Train Loss: 0.4506, Val Loss: 0.4601, Val Acc: 0.8056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miki\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Train Loss: 0.3787, Val Loss: 0.6262, Val Acc: 0.7500\n",
      "Epoch: 120, Train Loss: 0.4169, Val Loss: 0.7170, Val Acc: 0.7500\n",
      "Epoch: 140, Train Loss: 0.4264, Val Loss: 0.7812, Val Acc: 0.7222\n",
      "Training fold 2/5\n",
      "Epoch: 20, Train Loss: 0.7077, Val Loss: 1.4389, Val Acc: 0.6667\n",
      "Epoch: 40, Train Loss: 0.5967, Val Loss: 0.9697, Val Acc: 0.7778\n",
      "Epoch: 60, Train Loss: 0.5520, Val Loss: 1.2327, Val Acc: 0.6667\n",
      "Epoch: 80, Train Loss: 0.3292, Val Loss: 0.9642, Val Acc: 0.7778\n",
      "Epoch: 100, Train Loss: 0.3407, Val Loss: 1.0939, Val Acc: 0.7222\n",
      "Epoch: 120, Train Loss: 0.5056, Val Loss: 0.7921, Val Acc: 0.7778\n",
      "Epoch: 140, Train Loss: 0.6006, Val Loss: 1.2096, Val Acc: 0.6111\n",
      "Training fold 3/5\n",
      "Epoch: 20, Train Loss: 1.6046, Val Loss: 3.2666, Val Acc: 0.5000\n",
      "Epoch: 40, Train Loss: 0.5756, Val Loss: 1.0343, Val Acc: 0.6944\n",
      "Epoch: 60, Train Loss: 0.5001, Val Loss: 0.7268, Val Acc: 0.7778\n",
      "Epoch: 80, Train Loss: 0.4122, Val Loss: 0.7273, Val Acc: 0.7222\n",
      "Epoch: 100, Train Loss: 0.3717, Val Loss: 0.7088, Val Acc: 0.7222\n",
      "Epoch: 120, Train Loss: 0.3838, Val Loss: 0.6363, Val Acc: 0.8056\n",
      "Epoch: 140, Train Loss: 0.3717, Val Loss: 1.0170, Val Acc: 0.7222\n",
      "Training fold 4/5\n",
      "Epoch: 20, Train Loss: 1.4368, Val Loss: 1.2025, Val Acc: 0.8056\n",
      "Epoch: 40, Train Loss: 1.0716, Val Loss: 0.8688, Val Acc: 0.8056\n",
      "Epoch: 60, Train Loss: 0.6024, Val Loss: 1.2457, Val Acc: 0.5833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miki\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80, Train Loss: 0.6558, Val Loss: 0.6452, Val Acc: 0.7778\n",
      "Epoch: 100, Train Loss: 0.5047, Val Loss: 1.0370, Val Acc: 0.8333\n",
      "Epoch: 120, Train Loss: 0.4609, Val Loss: 0.6854, Val Acc: 0.7500\n",
      "Epoch: 140, Train Loss: 0.4620, Val Loss: 0.5204, Val Acc: 0.8333\n",
      "Training fold 5/5\n",
      "Epoch: 20, Train Loss: 0.9094, Val Loss: 1.4703, Val Acc: 0.6111\n",
      "Epoch: 40, Train Loss: 0.4870, Val Loss: 1.2212, Val Acc: 0.5278\n",
      "Epoch: 60, Train Loss: 0.4869, Val Loss: 0.9217, Val Acc: 0.6667\n",
      "Epoch: 80, Train Loss: 0.4277, Val Loss: 1.3759, Val Acc: 0.6389\n",
      "Epoch: 100, Train Loss: 0.3905, Val Loss: 0.7645, Val Acc: 0.6667\n",
      "Epoch: 120, Train Loss: 0.3964, Val Loss: 1.0745, Val Acc: 0.7222\n",
      "Epoch: 140, Train Loss: 0.3831, Val Loss: 1.2130, Val Acc: 0.6389\n",
      "Average PR-AUC: 0.2557\n",
      "Optimal threshold (balanced accuracy = 0.5916): 0.2745\n",
      "Optimal Threshold - F1: 0.3964, Precision: 0.3188, Recall: 0.5238\n",
      "\n",
      "Fixed Threshold (0.5) Results:\n",
      "Balanced Accuracy: 0.5564\n",
      "F1 Score: 0.3368\n",
      "Precision: 0.3019\n",
      "Recall: 0.3810\n",
      "\n",
      "Hyperparameter combination 6/12:\n",
      "{'hidden_features': 32, 'num_heads': 8, 'dropout': 0.5, 'lr': 0.01, 'weight_decay': 0.0005, 'use_class_weights': False}\n",
      "Training fold 1/5\n",
      "Epoch: 20, Train Loss: 1.7978, Val Loss: 1.3433, Val Acc: 0.7778\n",
      "Epoch: 40, Train Loss: 0.8116, Val Loss: 1.4522, Val Acc: 0.8333\n",
      "Epoch: 60, Train Loss: 0.5274, Val Loss: 0.9230, Val Acc: 0.7500\n",
      "Epoch: 80, Train Loss: 0.7426, Val Loss: 0.6862, Val Acc: 0.6667\n",
      "Epoch: 100, Train Loss: 0.5587, Val Loss: 0.8528, Val Acc: 0.7500\n",
      "Epoch: 120, Train Loss: 0.8638, Val Loss: 0.6476, Val Acc: 0.7778\n",
      "Epoch: 140, Train Loss: 0.4958, Val Loss: 0.5813, Val Acc: 0.7778\n",
      "Training fold 2/5\n",
      "Epoch: 20, Train Loss: 0.8013, Val Loss: 2.8976, Val Acc: 0.6111\n",
      "Epoch: 40, Train Loss: 0.9023, Val Loss: 1.1832, Val Acc: 0.7500\n",
      "Epoch: 60, Train Loss: 0.5682, Val Loss: 0.8859, Val Acc: 0.6111\n",
      "Epoch: 80, Train Loss: 0.9208, Val Loss: 5.2623, Val Acc: 0.7500\n",
      "Epoch: 100, Train Loss: 0.4317, Val Loss: 1.7930, Val Acc: 0.6667\n",
      "Epoch: 120, Train Loss: 0.4270, Val Loss: 1.9821, Val Acc: 0.6389\n",
      "Epoch: 140, Train Loss: 0.4759, Val Loss: 1.1677, Val Acc: 0.7500\n",
      "Training fold 3/5\n",
      "Epoch: 20, Train Loss: 2.0241, Val Loss: 0.9705, Val Acc: 0.7500\n",
      "Epoch: 40, Train Loss: 0.9487, Val Loss: 3.8921, Val Acc: 0.6667\n",
      "Epoch: 60, Train Loss: 0.9866, Val Loss: 2.7479, Val Acc: 0.6944\n",
      "Epoch: 80, Train Loss: 1.4254, Val Loss: 0.9691, Val Acc: 0.8056\n",
      "Epoch: 100, Train Loss: 2.5694, Val Loss: 1.2816, Val Acc: 0.7222\n",
      "Epoch: 120, Train Loss: 1.8521, Val Loss: 1.7830, Val Acc: 0.6944\n",
      "Epoch: 140, Train Loss: 1.3216, Val Loss: 1.4299, Val Acc: 0.7778\n",
      "Training fold 4/5\n",
      "Epoch: 20, Train Loss: 2.5938, Val Loss: 1.3403, Val Acc: 0.6389\n",
      "Epoch: 40, Train Loss: 1.1076, Val Loss: 1.3121, Val Acc: 0.6111\n",
      "Epoch: 60, Train Loss: 0.7444, Val Loss: 1.5508, Val Acc: 0.7222\n",
      "Epoch: 80, Train Loss: 0.5406, Val Loss: 0.7799, Val Acc: 0.6389\n",
      "Epoch: 100, Train Loss: 0.5850, Val Loss: 0.6524, Val Acc: 0.8056\n",
      "Epoch: 120, Train Loss: 0.5652, Val Loss: 1.0670, Val Acc: 0.7222\n",
      "Epoch: 140, Train Loss: 0.5862, Val Loss: 0.5272, Val Acc: 0.8056\n",
      "Training fold 5/5\n",
      "Epoch: 20, Train Loss: 1.8011, Val Loss: 1.8448, Val Acc: 0.6944\n",
      "Epoch: 40, Train Loss: 1.2606, Val Loss: 1.7899, Val Acc: 0.6944\n",
      "Epoch: 60, Train Loss: 0.7918, Val Loss: 1.4137, Val Acc: 0.6944\n",
      "Epoch: 80, Train Loss: 0.5150, Val Loss: 1.0799, Val Acc: 0.6111\n",
      "Epoch: 100, Train Loss: 0.4868, Val Loss: 1.4115, Val Acc: 0.6111\n",
      "Epoch: 120, Train Loss: 0.4580, Val Loss: 1.2303, Val Acc: 0.6111\n",
      "Epoch: 140, Train Loss: 0.4470, Val Loss: 0.6821, Val Acc: 0.6944\n",
      "Average PR-AUC: 0.2733\n",
      "Optimal threshold (balanced accuracy = 0.5595): 0.0449\n",
      "Optimal Threshold - F1: 0.3952, Precision: 0.2640, Recall: 0.7857\n",
      "\n",
      "Fixed Threshold (0.5) Results:\n",
      "Balanced Accuracy: 0.5450\n",
      "F1 Score: 0.2963\n",
      "Precision: 0.3077\n",
      "Recall: 0.2857\n",
      "\n",
      "Hyperparameter combination 7/12:\n",
      "{'hidden_features': 8, 'num_heads': 4, 'dropout': 0.3, 'lr': 0.0005, 'weight_decay': 0.0001, 'use_class_weights': False}\n",
      "Training fold 1/5\n",
      "Epoch: 20, Train Loss: 0.5789, Val Loss: 0.5359, Val Acc: 0.7222\n",
      "Epoch: 40, Train Loss: 0.5406, Val Loss: 0.6876, Val Acc: 0.6389\n",
      "Epoch: 60, Train Loss: 0.4889, Val Loss: 0.5902, Val Acc: 0.7500\n",
      "Epoch: 80, Train Loss: 0.4460, Val Loss: 0.4984, Val Acc: 0.7500\n",
      "Epoch: 100, Train Loss: 0.4410, Val Loss: 0.4868, Val Acc: 0.7500\n",
      "Epoch: 120, Train Loss: 0.4304, Val Loss: 0.6261, Val Acc: 0.7500\n",
      "Epoch: 140, Train Loss: 0.4332, Val Loss: 0.5397, Val Acc: 0.7500\n",
      "Training fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miki\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Train Loss: 0.5372, Val Loss: 0.6772, Val Acc: 0.7500\n",
      "Epoch: 40, Train Loss: 0.4924, Val Loss: 0.5862, Val Acc: 0.7778\n",
      "Epoch: 60, Train Loss: 0.4258, Val Loss: 0.5828, Val Acc: 0.7222\n",
      "Epoch: 80, Train Loss: 0.4024, Val Loss: 0.7018, Val Acc: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miki\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Train Loss: 0.3824, Val Loss: 0.6643, Val Acc: 0.7500\n",
      "Epoch: 120, Train Loss: 0.4026, Val Loss: 0.7948, Val Acc: 0.6944\n",
      "Epoch: 140, Train Loss: 0.3541, Val Loss: 0.7074, Val Acc: 0.6944\n",
      "Training fold 3/5\n",
      "Epoch: 20, Train Loss: 0.5198, Val Loss: 0.5748, Val Acc: 0.6944\n",
      "Epoch: 40, Train Loss: 0.4510, Val Loss: 0.6337, Val Acc: 0.7500\n",
      "Epoch: 60, Train Loss: 0.4425, Val Loss: 0.6220, Val Acc: 0.6389\n",
      "Epoch: 80, Train Loss: 0.4161, Val Loss: 0.6325, Val Acc: 0.6667\n",
      "Epoch: 100, Train Loss: 0.3844, Val Loss: 0.5855, Val Acc: 0.7222\n",
      "Epoch: 120, Train Loss: 0.3583, Val Loss: 0.6776, Val Acc: 0.6111\n",
      "Epoch: 140, Train Loss: 0.3178, Val Loss: 0.8640, Val Acc: 0.6111\n",
      "Training fold 4/5\n",
      "Epoch: 20, Train Loss: 0.7327, Val Loss: 0.7506, Val Acc: 0.5833\n",
      "Epoch: 40, Train Loss: 0.5478, Val Loss: 0.5226, Val Acc: 0.7778\n",
      "Epoch: 60, Train Loss: 0.5189, Val Loss: 0.5017, Val Acc: 0.7500\n",
      "Epoch: 80, Train Loss: 0.4843, Val Loss: 0.3743, Val Acc: 0.8889\n",
      "Epoch: 100, Train Loss: 0.4875, Val Loss: 0.4507, Val Acc: 0.7778\n",
      "Epoch: 120, Train Loss: 0.4838, Val Loss: 0.4786, Val Acc: 0.8333\n",
      "Epoch: 140, Train Loss: 0.4109, Val Loss: 0.5701, Val Acc: 0.7222\n",
      "Training fold 5/5\n",
      "Epoch: 20, Train Loss: 0.5934, Val Loss: 0.6481, Val Acc: 0.6667\n",
      "Epoch: 40, Train Loss: 0.4702, Val Loss: 0.6942, Val Acc: 0.6667\n",
      "Epoch: 60, Train Loss: 0.4923, Val Loss: 0.7118, Val Acc: 0.6389\n",
      "Epoch: 80, Train Loss: 0.4471, Val Loss: 0.6148, Val Acc: 0.7222\n",
      "Epoch: 100, Train Loss: 0.4354, Val Loss: 0.7187, Val Acc: 0.6944\n",
      "Epoch: 120, Train Loss: 0.3870, Val Loss: 0.7121, Val Acc: 0.6944\n",
      "Epoch: 140, Train Loss: 0.4086, Val Loss: 0.5994, Val Acc: 0.7222\n",
      "Average PR-AUC: 0.3585\n",
      "Optimal threshold (balanced accuracy = 0.5880): 0.3276\n",
      "Optimal Threshold - F1: 0.3659, Precision: 0.3750, Recall: 0.3571\n",
      "\n",
      "Fixed Threshold (0.5) Results:\n",
      "Balanced Accuracy: 0.5207\n",
      "F1 Score: 0.1935\n",
      "Precision: 0.3000\n",
      "Recall: 0.1429\n",
      "\n",
      "Hyperparameter combination 8/12:\n",
      "{'hidden_features': 8, 'num_heads': 4, 'dropout': 0.5, 'lr': 0.01, 'weight_decay': 0.0001, 'use_class_weights': True}\n",
      "Training fold 1/5\n",
      "Epoch: 20, Train Loss: 1.3462, Val Loss: 0.9599, Val Acc: 0.5833\n",
      "Epoch: 40, Train Loss: 1.0857, Val Loss: 1.1999, Val Acc: 0.5833\n",
      "Epoch: 60, Train Loss: 0.8109, Val Loss: 1.0381, Val Acc: 0.5000\n",
      "Epoch: 80, Train Loss: 0.7411, Val Loss: 0.7651, Val Acc: 0.7222\n",
      "Epoch: 100, Train Loss: 0.8394, Val Loss: 1.0401, Val Acc: 0.6944\n",
      "Epoch: 120, Train Loss: 0.8599, Val Loss: 0.8436, Val Acc: 0.6111\n",
      "Epoch: 140, Train Loss: 0.8285, Val Loss: 0.7012, Val Acc: 0.7222\n",
      "Training fold 2/5\n",
      "Epoch: 20, Train Loss: 0.8529, Val Loss: 0.5719, Val Acc: 0.5556\n",
      "Epoch: 40, Train Loss: 0.7330, Val Loss: 0.9202, Val Acc: 0.5833\n",
      "Epoch: 60, Train Loss: 0.7315, Val Loss: 1.3188, Val Acc: 0.5278\n",
      "Epoch: 80, Train Loss: 0.6679, Val Loss: 1.1401, Val Acc: 0.5556\n",
      "Epoch: 100, Train Loss: 0.5211, Val Loss: 1.2580, Val Acc: 0.5556\n",
      "Epoch: 120, Train Loss: 0.6803, Val Loss: 0.9314, Val Acc: 0.6944\n",
      "Epoch: 140, Train Loss: 0.5955, Val Loss: 1.3686, Val Acc: 0.5278\n",
      "Training fold 3/5\n",
      "Epoch: 20, Train Loss: 0.8746, Val Loss: 0.9022, Val Acc: 0.5278\n",
      "Epoch: 40, Train Loss: 0.9578, Val Loss: 0.7456, Val Acc: 0.5556\n",
      "Epoch: 60, Train Loss: 0.7992, Val Loss: 0.8663, Val Acc: 0.5278\n",
      "Epoch: 80, Train Loss: 0.8059, Val Loss: 0.9830, Val Acc: 0.4444\n",
      "Epoch: 100, Train Loss: 0.7148, Val Loss: 1.0847, Val Acc: 0.3889\n",
      "Epoch: 120, Train Loss: 0.7117, Val Loss: 1.4482, Val Acc: 0.5000\n",
      "Epoch: 140, Train Loss: 0.7331, Val Loss: 1.4776, Val Acc: 0.5000\n",
      "Training fold 4/5\n",
      "Epoch: 20, Train Loss: 1.9348, Val Loss: 1.2351, Val Acc: 0.5000\n",
      "Epoch: 40, Train Loss: 1.2579, Val Loss: 0.8639, Val Acc: 0.4722\n",
      "Epoch: 60, Train Loss: 1.1036, Val Loss: 1.0160, Val Acc: 0.4444\n",
      "Epoch: 80, Train Loss: 1.3085, Val Loss: 1.0208, Val Acc: 0.5000\n",
      "Epoch: 100, Train Loss: 0.8697, Val Loss: 1.1255, Val Acc: 0.6944\n",
      "Epoch: 120, Train Loss: 0.8636, Val Loss: 0.8283, Val Acc: 0.5833\n",
      "Epoch: 140, Train Loss: 0.9034, Val Loss: 0.9799, Val Acc: 0.3889\n",
      "Training fold 5/5\n",
      "Epoch: 20, Train Loss: 1.2047, Val Loss: 1.9221, Val Acc: 0.6111\n",
      "Epoch: 40, Train Loss: 1.0077, Val Loss: 0.7594, Val Acc: 0.6111\n",
      "Epoch: 60, Train Loss: 0.8332, Val Loss: 1.1280, Val Acc: 0.4722\n",
      "Epoch: 80, Train Loss: 0.7899, Val Loss: 1.5057, Val Acc: 0.5556\n",
      "Epoch: 100, Train Loss: 0.7808, Val Loss: 0.8890, Val Acc: 0.5556\n",
      "Epoch: 120, Train Loss: 0.7474, Val Loss: 0.9751, Val Acc: 0.6667\n",
      "Epoch: 140, Train Loss: 0.7199, Val Loss: 0.8029, Val Acc: 0.6111\n",
      "Average PR-AUC: 0.3055\n",
      "Optimal threshold (balanced accuracy = 0.5968): 0.7552\n",
      "Optimal Threshold - F1: 0.3662, Precision: 0.4483, Recall: 0.3095\n",
      "\n",
      "Fixed Threshold (0.5) Results:\n",
      "Balanced Accuracy: 0.5637\n",
      "F1 Score: 0.3441\n",
      "Precision: 0.3137\n",
      "Recall: 0.3810\n",
      "\n",
      "Hyperparameter combination 9/12:\n",
      "{'hidden_features': 8, 'num_heads': 4, 'dropout': 0.5, 'lr': 0.01, 'weight_decay': 0.0005, 'use_class_weights': True}\n",
      "Training fold 1/5\n",
      "Epoch: 20, Train Loss: 1.0212, Val Loss: 0.6507, Val Acc: 0.7222\n",
      "Epoch: 40, Train Loss: 0.8802, Val Loss: 0.8138, Val Acc: 0.3333\n",
      "Epoch: 60, Train Loss: 0.8655, Val Loss: 0.8058, Val Acc: 0.5833\n",
      "Epoch: 80, Train Loss: 0.8717, Val Loss: 0.5414, Val Acc: 0.7500\n",
      "Epoch: 100, Train Loss: 0.8264, Val Loss: 0.7397, Val Acc: 0.6667\n",
      "Epoch: 120, Train Loss: 0.8605, Val Loss: 0.7035, Val Acc: 0.6111\n",
      "Epoch: 140, Train Loss: 0.6959, Val Loss: 0.6076, Val Acc: 0.7222\n",
      "Training fold 2/5\n",
      "Epoch: 20, Train Loss: 2.0456, Val Loss: 2.6067, Val Acc: 0.5000\n",
      "Epoch: 40, Train Loss: 1.3193, Val Loss: 1.1177, Val Acc: 0.3889\n",
      "Epoch: 60, Train Loss: 1.1000, Val Loss: 0.9161, Val Acc: 0.4722\n",
      "Epoch: 80, Train Loss: 0.8909, Val Loss: 0.8750, Val Acc: 0.4444\n",
      "Epoch: 100, Train Loss: 0.8492, Val Loss: 0.8578, Val Acc: 0.5833\n",
      "Epoch: 120, Train Loss: 0.8706, Val Loss: 1.5963, Val Acc: 0.6667\n",
      "Epoch: 140, Train Loss: 0.8596, Val Loss: 0.7319, Val Acc: 0.5556\n",
      "Training fold 3/5\n",
      "Epoch: 20, Train Loss: 1.0513, Val Loss: 1.5367, Val Acc: 0.5278\n",
      "Epoch: 40, Train Loss: 0.9253, Val Loss: 1.2988, Val Acc: 0.5000\n",
      "Epoch: 60, Train Loss: 0.8580, Val Loss: 0.6445, Val Acc: 0.5278\n",
      "Epoch: 80, Train Loss: 0.7787, Val Loss: 0.7604, Val Acc: 0.6667\n",
      "Epoch: 100, Train Loss: 1.2039, Val Loss: 1.2663, Val Acc: 0.3889\n",
      "Epoch: 120, Train Loss: 0.8915, Val Loss: 0.8686, Val Acc: 0.5278\n",
      "Epoch: 140, Train Loss: 0.8781, Val Loss: 0.5574, Val Acc: 0.6667\n",
      "Training fold 4/5\n",
      "Epoch: 20, Train Loss: 3.6455, Val Loss: 1.0970, Val Acc: 0.4444\n",
      "Epoch: 40, Train Loss: 0.8690, Val Loss: 0.7385, Val Acc: 0.5000\n",
      "Epoch: 60, Train Loss: 1.1718, Val Loss: 0.6401, Val Acc: 0.6944\n",
      "Epoch: 80, Train Loss: 0.9649, Val Loss: 0.6677, Val Acc: 0.5278\n",
      "Epoch: 100, Train Loss: 0.8192, Val Loss: 1.0120, Val Acc: 0.6667\n",
      "Epoch: 120, Train Loss: 0.8861, Val Loss: 0.8242, Val Acc: 0.5000\n",
      "Epoch: 140, Train Loss: 0.8198, Val Loss: 0.7656, Val Acc: 0.4444\n",
      "Training fold 5/5\n",
      "Epoch: 20, Train Loss: 0.9587, Val Loss: 0.9732, Val Acc: 0.4167\n",
      "Epoch: 40, Train Loss: 1.0193, Val Loss: 0.7993, Val Acc: 0.5556\n",
      "Epoch: 60, Train Loss: 0.7966, Val Loss: 0.8438, Val Acc: 0.6944\n",
      "Epoch: 80, Train Loss: 1.1173, Val Loss: 1.1461, Val Acc: 0.6111\n",
      "Epoch: 100, Train Loss: 0.8573, Val Loss: 0.6206, Val Acc: 0.6667\n",
      "Epoch: 120, Train Loss: 0.8100, Val Loss: 0.6614, Val Acc: 0.7222\n",
      "Epoch: 140, Train Loss: 0.8752, Val Loss: 0.6812, Val Acc: 0.6111\n",
      "Average PR-AUC: 0.3414\n",
      "Optimal threshold (balanced accuracy = 0.5932): 0.5713\n",
      "Optimal Threshold - F1: 0.3922, Precision: 0.3333, Recall: 0.4762\n",
      "\n",
      "Fixed Threshold (0.5) Results:\n",
      "Balanced Accuracy: 0.5590\n",
      "F1 Score: 0.3667\n",
      "Precision: 0.2821\n",
      "Recall: 0.5238\n",
      "\n",
      "Hyperparameter combination 10/12:\n",
      "{'hidden_features': 8, 'num_heads': 4, 'dropout': 0.3, 'lr': 0.001, 'weight_decay': 0.0005, 'use_class_weights': False}\n",
      "Training fold 1/5\n",
      "Epoch: 20, Train Loss: 0.6393, Val Loss: 0.6326, Val Acc: 0.6389\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_curve, auc, f1_score, accuracy_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "class FlowGAT(torch.nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, num_heads=8, dropout=0.6):\n",
    "        super(FlowGAT, self).__init__()\n",
    "        \n",
    "        # First GAT layer with multiple attention heads\n",
    "        self.gat1 = GATConv(\n",
    "            in_features, \n",
    "            hidden_features, \n",
    "            heads=num_heads, \n",
    "            dropout=dropout,\n",
    "            concat=True  # Concatenate the outputs of all heads\n",
    "        )\n",
    "        \n",
    "        # Second GAT layer with a single attention head for final prediction\n",
    "        self.gat2 = GATConv(\n",
    "            hidden_features * num_heads,\n",
    "            out_features,\n",
    "            heads=1,\n",
    "            dropout=dropout,\n",
    "            concat=False  # Single head output\n",
    "        )\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        \"\"\"\n",
    "        Forward pass through the FlowGAT model.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        x : torch.Tensor\n",
    "            Node features\n",
    "        edge_index : torch.Tensor\n",
    "            Graph connectivity in COO format\n",
    "        edge_weight : torch.Tensor, optional\n",
    "            Edge weights\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        torch.Tensor\n",
    "            Output predictions (raw logits, without sigmoid)\n",
    "        \"\"\"\n",
    "        # First GAT layer with ReLU activation\n",
    "        x = self.gat1(x, edge_index, edge_weight)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Second GAT layer\n",
    "        x = self.gat2(x, edge_index, edge_weight)\n",
    "        \n",
    "        # Return raw logits (without sigmoid)\n",
    "        return x\n",
    "\n",
    "def prepare_graph_data(adjacency_matrix, fpe_features, reaction_essentiality): \n",
    "    # Use NumPy to get nonzero indices and values (efficient)\n",
    "    rows, cols = np.nonzero(adjacency_matrix)  \n",
    "    edge_index = torch.tensor(np.vstack((rows, cols)), dtype=torch.long)\n",
    "    edge_weight = torch.tensor(adjacency_matrix[rows, cols], dtype=torch.float)\n",
    "\n",
    "    # Convert FPE features to tensor\n",
    "    x = torch.tensor(fpe_features, dtype=torch.float)\n",
    "\n",
    "    # Create graph data object\n",
    "    data = Data(x=x, edge_index=edge_index, edge_weight=edge_weight)\n",
    "\n",
    "    # Extract labeled nodes (excluding -1)\n",
    "    labeled_indices = []\n",
    "    labels = []\n",
    "    \n",
    "    for idx, (rxn_id, label) in enumerate(reaction_essentiality.items()):\n",
    "        if label != -1:  # Only include valid labels\n",
    "            labeled_indices.append(idx)\n",
    "            labels.append(label)\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    labeled_indices = torch.tensor(labeled_indices, dtype=torch.long)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    return data, labeled_indices, labels\n",
    "\n",
    "\n",
    "def prepare_graph_data_from_mfg(X_with_labels):\n",
    "    # Extract features and labels from the DataFrame\n",
    "    features = X_with_labels.drop('essentiality', axis=1).values\n",
    "    labels_series = X_with_labels['essentiality']\n",
    "    \n",
    "    # Get node indices and their labels\n",
    "    all_indices = np.arange(len(labels_series))\n",
    "    labeled_mask = labels_series != -1\n",
    "    labeled_indices = all_indices[labeled_mask]\n",
    "    labels = labels_series[labeled_mask].values\n",
    "    \n",
    "    # Extract the original adjacency matrix from the features\n",
    "    num_nodes = features.shape[0]\n",
    "    adjacency_matrix = features[:, :num_nodes]  # First half contains M_k\n",
    "    \n",
    "    # Get edge index and weights from adjacency matrix\n",
    "    rows, cols = np.nonzero(adjacency_matrix)  \n",
    "    edge_index = torch.tensor(np.vstack((rows, cols)), dtype=torch.long)\n",
    "    edge_weight = torch.tensor(adjacency_matrix[rows, cols], dtype=torch.float)\n",
    "    \n",
    "    # Convert features to tensor\n",
    "    x = torch.tensor(features, dtype=torch.float)\n",
    "    \n",
    "    # Create graph data object\n",
    "    data = Data(x=x, edge_index=edge_index, edge_weight=edge_weight)\n",
    "    \n",
    "    # Convert labeled indices and labels to tensors\n",
    "    labeled_indices = torch.tensor(labeled_indices, dtype=torch.long)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    return data, labeled_indices, labels\n",
    "\n",
    "def train_flowgat(data, labeled_indices, labels, hyperparams, n_splits=5, epochs=260):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data = data.to(device)\n",
    "    \n",
    "    # Extract hyperparameters\n",
    "    hidden_features = hyperparams['hidden_features']\n",
    "    num_heads = hyperparams['num_heads']\n",
    "    dropout = hyperparams['dropout']\n",
    "    lr = hyperparams['lr']\n",
    "    weight_decay = hyperparams['weight_decay']\n",
    "    \n",
    "    # Handle class imbalance\n",
    "    if hyperparams.get('use_class_weights', False):\n",
    "        # Calculate class weights for imbalanced dataset\n",
    "        # Make sure to handle both PyTorch tensors and NumPy arrays\n",
    "        if isinstance(labels, torch.Tensor):\n",
    "            num_pos = torch.sum(labels == 1).item()\n",
    "            num_neg = torch.sum(labels == 0).item()\n",
    "        else:\n",
    "            num_pos = np.sum(labels == 1)\n",
    "            num_neg = np.sum(labels == 0)\n",
    "        pos_weight = torch.tensor([num_neg / num_pos], dtype=torch.float).to(device)\n",
    "    else:\n",
    "        pos_weight = None\n",
    "    \n",
    "    # Convert labels to numpy for stratified split\n",
    "    labeled_indices_np = labeled_indices.cpu().numpy() if isinstance(labeled_indices, torch.Tensor) else np.array(labeled_indices)\n",
    "    labels_np = labels.cpu().numpy() if isinstance(labels, torch.Tensor) else np.array(labels)\n",
    "    \n",
    "    # Initialize stratified k-fold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Lists to store results\n",
    "    models = []\n",
    "    val_indices_list = []\n",
    "    predictions_list = []\n",
    "    true_labels_list = []\n",
    "    \n",
    "    # Collect training statistics\n",
    "    train_stats = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'val_accuracy': [],\n",
    "        'val_precision': [],\n",
    "        'val_recall': [],\n",
    "        'val_f1': []\n",
    "    }\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(labeled_indices_np, labels_np)):\n",
    "        print(f\"Training fold {fold+1}/{n_splits}\")\n",
    "        \n",
    "        # Get train and validation indices\n",
    "        train_mask = labeled_indices_np[train_idx]\n",
    "        val_mask = labeled_indices_np[val_idx]\n",
    "        \n",
    "        # Initialize model\n",
    "        in_features = data.x.shape[1]\n",
    "        model = FlowGAT(\n",
    "            in_features=in_features, \n",
    "            hidden_features=hidden_features, \n",
    "            out_features=1,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        ).to(device)\n",
    "        \n",
    "        # Initialize optimizer\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        \n",
    "        # Convert labels to PyTorch tensor\n",
    "        y = torch.tensor(labels_np, dtype=torch.float).to(device)\n",
    "        \n",
    "        # Training loop\n",
    "        fold_train_loss = []\n",
    "        fold_val_loss = []\n",
    "        fold_val_accuracy = []\n",
    "        fold_val_precision = []\n",
    "        fold_val_recall = []\n",
    "        fold_val_f1 = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            out = model(data.x, data.edge_index, data.edge_weight)\n",
    "            \n",
    "            # Calculate loss on training nodes (using BCE with logits since we removed sigmoid)\n",
    "            if pos_weight is not None:\n",
    "                loss = F.binary_cross_entropy_with_logits(\n",
    "                    out[train_mask].view(-1), \n",
    "                    y[train_idx], \n",
    "                    pos_weight=pos_weight\n",
    "                )\n",
    "            else:\n",
    "                loss = F.binary_cross_entropy_with_logits(\n",
    "                    out[train_mask].view(-1), \n",
    "                    y[train_idx]\n",
    "                )\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Print training progress\n",
    "            if (epoch + 1) % 20 == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_out = out[val_mask].view(-1)\n",
    "                    val_loss = F.binary_cross_entropy_with_logits(val_out, y[val_idx])\n",
    "                    \n",
    "                    # Apply sigmoid for predictions\n",
    "                    val_probs = torch.sigmoid(val_out)\n",
    "                    pred_binary = (val_probs > 0.5).float()\n",
    "                    \n",
    "                    # Calculate metrics\n",
    "                    val_labels_np = y[val_idx].cpu().numpy()\n",
    "                    pred_binary_np = pred_binary.cpu().numpy()\n",
    "                    \n",
    "                    accuracy = accuracy_score(val_labels_np, pred_binary_np)\n",
    "                    \n",
    "                    # Handle cases with no positive predictions or no positive labels\n",
    "                    try:\n",
    "                        prec = precision_score(val_labels_np, pred_binary_np)\n",
    "                    except:\n",
    "                        prec = 0.0\n",
    "                    \n",
    "                    try:\n",
    "                        rec = recall_score(val_labels_np, pred_binary_np)\n",
    "                    except:\n",
    "                        rec = 0.0\n",
    "                    \n",
    "                    try:\n",
    "                        f1 = f1_score(val_labels_np, pred_binary_np)\n",
    "                    except:\n",
    "                        f1 = 0.0\n",
    "                    \n",
    "                    print(f\"Epoch: {epoch+1}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, Val Acc: {accuracy:.4f}\")\n",
    "                    \n",
    "                    # Store metrics\n",
    "                    fold_train_loss.append(loss.item())\n",
    "                    fold_val_loss.append(val_loss.item())\n",
    "                    fold_val_accuracy.append(accuracy)\n",
    "                    fold_val_precision.append(prec)\n",
    "                    fold_val_recall.append(rec)\n",
    "                    fold_val_f1.append(f1)\n",
    "        \n",
    "        # Store fold statistics\n",
    "        train_stats['train_loss'].append(fold_train_loss)\n",
    "        train_stats['val_loss'].append(fold_val_loss)\n",
    "        train_stats['val_accuracy'].append(fold_val_accuracy)\n",
    "        train_stats['val_precision'].append(fold_val_precision)\n",
    "        train_stats['val_recall'].append(fold_val_recall)\n",
    "        train_stats['val_f1'].append(fold_val_f1)\n",
    "        \n",
    "        # Evaluate final model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(data.x, data.edge_index, data.edge_weight)\n",
    "            val_pred = torch.sigmoid(out[val_mask].view(-1)).cpu().numpy()\n",
    "        \n",
    "        # Store results\n",
    "        models.append(model)\n",
    "        val_indices_list.append(val_idx)\n",
    "        predictions_list.append(val_pred)\n",
    "        true_labels_list.append(y[val_idx].cpu().numpy())\n",
    "    \n",
    "    return models, val_indices_list, predictions_list, true_labels_list, train_stats\n",
    "\n",
    "'''\n",
    "def evaluate_results(val_indices_list, predictions_list, true_labels_list):\n",
    "   \n",
    "    # Flatten predictions and labels\n",
    "    all_preds = np.concatenate(predictions_list)\n",
    "    all_labels = np.concatenate(true_labels_list)\n",
    "    \n",
    "    # Calculate PRAUC\n",
    "    precision, recall, thresholds = precision_recall_curve(all_labels, all_preds)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    # Find optimal threshold based on F1 score\n",
    "    f1_scores = []\n",
    "    for t in thresholds:\n",
    "        try:\n",
    "            f1 = f1_score(all_labels, (all_preds >= t).astype(int))\n",
    "            f1_scores.append(f1)\n",
    "        except:\n",
    "            f1_scores.append(0.0)\n",
    "    \n",
    "    best_threshold_idx = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_threshold_idx]\n",
    "    \n",
    "    # Calculate metrics with optimal threshold\n",
    "    binary_preds = (all_preds >= best_threshold).astype(int)\n",
    "    f1 = f1_score(all_labels, binary_preds)\n",
    "    prec = precision_score(all_labels, binary_preds)\n",
    "    rec = recall_score(all_labels, binary_preds)\n",
    "    \n",
    "    # Plot precision-recall curve\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(recall, precision, label=f'PRAUC = {pr_auc:.4f}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('precision_recall_curve.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Average PR-AUC: {pr_auc:.4f}\")\n",
    "    print(f\"Average F1 Score (threshold={best_threshold:.4f}): {f1:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall: {rec:.4f}\")\n",
    "    \n",
    "    return pr_auc, f1, prec, rec\n",
    "'''\n",
    "def evaluate_results(val_indices_list, predictions_list, true_labels_list):\n",
    "    # Flatten predictions and labels\n",
    "    all_preds = np.concatenate(predictions_list)\n",
    "    all_labels = np.concatenate(true_labels_list)\n",
    "    \n",
    "    # Calculate PRAUC\n",
    "    precision, recall, thresholds = precision_recall_curve(all_labels, all_preds)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    # Find optimal threshold based on balanced accuracy\n",
    "    balanced_acc_scores = []\n",
    "    # Need to handle the case where thresholds might not include 0.5\n",
    "    all_thresholds = np.append(thresholds, [0.5])\n",
    "    all_thresholds = np.sort(all_thresholds)\n",
    "    \n",
    "    for t in all_thresholds:\n",
    "        binary_preds = (all_preds >= t).astype(int)\n",
    "        # Calculate balanced accuracy: (sensitivity + specificity) / 2\n",
    "        tn, fp, fn, tp = confusion_matrix(all_labels, binary_preds, labels=[0, 1]).ravel()\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        balanced_acc = (sensitivity + specificity) / 2\n",
    "        balanced_acc_scores.append(balanced_acc)\n",
    "    \n",
    "    best_threshold_idx = np.argmax(balanced_acc_scores)\n",
    "    best_threshold = all_thresholds[best_threshold_idx]\n",
    "    \n",
    "    # Calculate metrics with optimal threshold\n",
    "    binary_preds_optimal = (all_preds >= best_threshold).astype(int)\n",
    "    f1_optimal = f1_score(all_labels, binary_preds_optimal)\n",
    "    prec_optimal = precision_score(all_labels, binary_preds_optimal)\n",
    "    rec_optimal = recall_score(all_labels, binary_preds_optimal)\n",
    "    \n",
    "    # Calculate metrics with fixed 0.5 threshold\n",
    "    binary_preds_fixed = (all_preds >= 0.5).astype(int)\n",
    "    f1_fixed = f1_score(all_labels, binary_preds_fixed)\n",
    "    prec_fixed = precision_score(all_labels, binary_preds_fixed)\n",
    "    rec_fixed = recall_score(all_labels, binary_preds_fixed)\n",
    "    \n",
    "    # Calculate balanced accuracy at optimal threshold\n",
    "    tn_opt, fp_opt, fn_opt, tp_opt = confusion_matrix(all_labels, binary_preds_optimal, labels=[0, 1]).ravel()\n",
    "    sens_opt = tp_opt / (tp_opt + fn_opt) if (tp_opt + fn_opt) > 0 else 0\n",
    "    spec_opt = tn_opt / (tn_opt + fp_opt) if (tn_opt + fp_opt) > 0 else 0\n",
    "    balanced_acc_opt = (sens_opt + spec_opt) / 2\n",
    "    \n",
    "    # Calculate balanced accuracy at fixed threshold\n",
    "    tn_fix, fp_fix, fn_fix, tp_fix = confusion_matrix(all_labels, binary_preds_fixed, labels=[0, 1]).ravel()\n",
    "    sens_fix = tp_fix / (tp_fix + fn_fix) if (tp_fix + fn_fix) > 0 else 0\n",
    "    spec_fix = tn_fix / (tn_fix + fp_fix) if (tn_fix + fp_fix) > 0 else 0\n",
    "    balanced_acc_fix = (sens_fix + spec_fix) / 2\n",
    "    \n",
    "    # Plot precision-recall curve\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(recall, precision, label=f'PRAUC = {pr_auc:.4f}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('precision_recall_curve.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Average PR-AUC: {pr_auc:.4f}\")\n",
    "    print(f\"Optimal threshold (balanced accuracy = {balanced_acc_opt:.4f}): {best_threshold:.4f}\")\n",
    "    print(f\"Optimal Threshold - F1: {f1_optimal:.4f}, Precision: {prec_optimal:.4f}, Recall: {rec_optimal:.4f}\")\n",
    "    \n",
    "    print(\"\\nFixed Threshold (0.5) Results:\")\n",
    "    print(f\"Balanced Accuracy: {balanced_acc_fix:.4f}\")\n",
    "    print(f\"F1 Score: {f1_fixed:.4f}\")\n",
    "    print(f\"Precision: {prec_fixed:.4f}\")\n",
    "    print(f\"Recall: {rec_fixed:.4f}\")\n",
    "    \n",
    "    # Still return the original metrics for compatibility with existing code\n",
    "    return pr_auc, f1_optimal, prec_optimal, rec_optimal\n",
    "\n",
    "\n",
    "'''\n",
    "def evaluate_results(val_indices_list, predictions_list, true_labels_list):\n",
    "   \n",
    "    # Flatten predictions and labels\n",
    "    all_preds = np.concatenate(predictions_list)\n",
    "    all_labels = np.concatenate(true_labels_list)\n",
    "    \n",
    "    # Calculate PRAUC\n",
    "    precision, recall, thresholds = precision_recall_curve(all_labels, all_preds)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    # Find optimal threshold based on F1 score\n",
    "    f1_scores = []\n",
    "    for t in thresholds:\n",
    "        try:\n",
    "            f1 = f1_score(all_labels, (all_preds >= t).astype(int))\n",
    "            f1_scores.append(f1)\n",
    "        except:\n",
    "            f1_scores.append(0.0)\n",
    "    \n",
    "    best_threshold_idx = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_threshold_idx]\n",
    "    \n",
    "    # Calculate metrics with optimal threshold\n",
    "    binary_preds_optimal = (all_preds >= best_threshold).astype(int)\n",
    "    f1_optimal = f1_score(all_labels, binary_preds_optimal)\n",
    "    prec_optimal = precision_score(all_labels, binary_preds_optimal)\n",
    "    rec_optimal = recall_score(all_labels, binary_preds_optimal)\n",
    "    \n",
    "    # Also calculate metrics with fixed 0.5 threshold\n",
    "    binary_preds_fixed = (all_preds >= 0.5).astype(int)\n",
    "    f1_fixed = f1_score(all_labels, binary_preds_fixed)\n",
    "    prec_fixed = precision_score(all_labels, binary_preds_fixed)\n",
    "    rec_fixed = recall_score(all_labels, binary_preds_fixed)\n",
    "    #pr_auc = auc(recall, precision)\n",
    "    \n",
    "    # Plot precision-recall curve\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(recall, precision, label=f'PRAUC = {pr_auc:.4f}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('precision_recall_curve.png')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Average PR-AUC: {pr_auc:.4f}\")\n",
    "    print(f\"Average F1 Score (optimal threshold={best_threshold:.4f}): {f1_optimal:.4f}\")\n",
    "    print(f\"Optimal Threshold - Precision: {prec_optimal:.4f}, Recall: {rec_optimal:.4f}\")\n",
    "    \n",
    "    print(\"\\nFixed Threshold (0.5) Results:\")\n",
    "    print(f\"F1 Score: {f1_fixed:.4f}\")\n",
    "    print(f\"Precision: {prec_fixed:.4f}\")\n",
    "    print(f\"Recall: {rec_fixed:.4f}\")\n",
    "    \n",
    "    # Still return the original metrics for compatibility with existing code\n",
    "    return pr_auc, f1_optimal, prec_optimal, rec_optimal\n",
    "'''\n",
    "def grid_search_flowgat(data, labeled_indices, labels, n_splits=5, cv_epochs=140):\n",
    "    # Define hyperparameter grid\n",
    "    param_grid = {\n",
    "        'hidden_features': [8, 16, 32],\n",
    "        'num_heads': [4, 8],\n",
    "        'dropout': [0.3, 0.5],\n",
    "        'lr': [0.01, 0.005, 0.001,0.0005],\n",
    "        'weight_decay': [5e-4, 1e-4],\n",
    "        'use_class_weights': [True, False]\n",
    "    }\n",
    "    \n",
    "    # Handle case where use_class_weights is a boolean instead of a list\n",
    "    for key in param_grid:\n",
    "        if not isinstance(param_grid[key], list):\n",
    "            param_grid[key] = [param_grid[key]]\n",
    "    \n",
    "    # Choose a subset of hyperparameter combinations to test\n",
    "    keys = list(param_grid.keys())\n",
    "    values = list(param_grid.values())\n",
    "    combinations = list(itertools.product(*values))\n",
    "    \n",
    "    # Sample combinations if there are too many\n",
    "    max_combinations = 12  # Adjust based on your computational resources\n",
    "    if len(combinations) > max_combinations:\n",
    "        np.random.seed(42)\n",
    "        indices = np.random.choice(len(combinations), max_combinations, replace=False)\n",
    "        combinations = [combinations[i] for i in indices]\n",
    "    \n",
    "    # Initialize results tracking\n",
    "    results = []\n",
    "    best_prauc = 0.0\n",
    "    best_params = None\n",
    "    \n",
    "    # Iterate through parameter combinations\n",
    "    for i, params in enumerate(combinations):\n",
    "        hyperparams = {keys[j]: params[j] for j in range(len(keys))}\n",
    "        print(f\"\\nHyperparameter combination {i+1}/{len(combinations)}:\")\n",
    "        print(hyperparams)\n",
    "        \n",
    "        # Train and evaluate model with current hyperparameters\n",
    "        models, val_indices_list, predictions_list, true_labels_list, _ = train_flowgat(\n",
    "            data, \n",
    "            labeled_indices, \n",
    "            labels, \n",
    "            hyperparams, \n",
    "            n_splits=n_splits, \n",
    "            epochs=cv_epochs\n",
    "        )\n",
    "        \n",
    "        # Evaluate model\n",
    "        pr_auc, f1, precision, recall = evaluate_results(val_indices_list, predictions_list, true_labels_list)\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            **hyperparams,\n",
    "            'prauc': pr_auc,\n",
    "            'f1': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        }\n",
    "        results.append(result)\n",
    "        \n",
    "        # Update best parameters\n",
    "        if pr_auc > best_prauc:\n",
    "            best_prauc = pr_auc\n",
    "            best_params = hyperparams\n",
    "    \n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Sort by PR-AUC\n",
    "    results_df = results_df.sort_values('prauc', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\nGrid Search Results:\")\n",
    "    print(results_df.head())\n",
    "    \n",
    "    print(\"\\nBest Hyperparameters:\")\n",
    "    print(best_params)\n",
    "    print(f\"Best PR-AUC: {best_prauc:.4f}\")\n",
    "    \n",
    "    # Save results to CSV\n",
    "    results_df.to_csv('grid_search_results.csv', index=False)\n",
    "    \n",
    "    return best_params, best_prauc, results_df\n",
    "\n",
    "def train_and_evaluate_final_model(data, labeled_indices, labels, best_params, n_splits=5, epochs=260):\n",
    "    # Train final model with best hyperparameters\n",
    "    models, val_indices_list, predictions_list, true_labels_list, train_stats = train_flowgat(\n",
    "        data, \n",
    "        labeled_indices, \n",
    "        labels, \n",
    "        best_params, \n",
    "        n_splits=n_splits, \n",
    "        epochs=epochs\n",
    "    )\n",
    "    \n",
    "    # Evaluate final model\n",
    "    pr_auc, f1, precision, recall = evaluate_results(val_indices_list, predictions_list, true_labels_list)\n",
    "    \n",
    "    # Compile metrics\n",
    "    metrics = {\n",
    "        'prauc': pr_auc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "    \n",
    "    # Plot training curves\n",
    "    #plot_training_curves(train_stats)\n",
    "    \n",
    "    return models, metrics, train_stats\n",
    "\n",
    "def predict_with_flowgat(models, data):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data = data.to(device)\n",
    "    \n",
    "    # Make predictions with each model\n",
    "    all_preds = []\n",
    "    for model in models:\n",
    "        #model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Get raw logits and apply sigmoid\n",
    "            logits = model(data.x, data.edge_index, data.edge_weight).view(-1)\n",
    "            pred_probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            all_preds.append(pred_probs)\n",
    "    \n",
    "    # Average predictions\n",
    "    ensemble_preds = np.mean(all_preds, axis=0)\n",
    "    \n",
    "    return ensemble_preds\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data, labeled_indices, labels = prepare_graph_data_from_mfg(X_with_labels)\n",
    "    \n",
    "    \n",
    "    best_params, best_prauc, results_df = grid_search_flowgat(data, labeled_indices, labels)\n",
    "    \n",
    "    # Example of training final model\n",
    "    \n",
    "    models, metrics, train_stats = train_and_evaluate_final_model(data, labeled_indices, labels, best_params)\n",
    "\n",
    "    ensemble_predictions = predict_with_flowgat(models, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8e03f0e3-466d-4a03-bde4-d6f84e6178d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miki\\AppData\\Local\\Temp\\ipykernel_33760\\245771662.py:8: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  labeled_indices_np = np.array(labeled_indices)\n",
      "C:\\Users\\Miki\\AppData\\Local\\Temp\\ipykernel_33760\\245771662.py:9: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  labels_np = np.array(labels)\n"
     ]
    }
   ],
   "source": [
    "prediction_df = pd.DataFrame({\n",
    "    'node_index': range(len(ensemble_predictions)),\n",
    "    'prediction_score': ensemble_predictions,\n",
    "    'predicted_class': (ensemble_predictions >= 0.5).astype(int)\n",
    "})\n",
    "\n",
    "# Add actual labels for nodes that have them\n",
    "labeled_indices_np = np.array(labeled_indices)\n",
    "labels_np = np.array(labels)\n",
    "for i, idx in enumerate(labeled_indices_np):\n",
    "    prediction_df.loc[prediction_df['node_index'] == idx, 'true_label'] = labels_np[i]\n",
    "\n",
    "# Calculate error type (FP, FN, TP, TN)\n",
    "prediction_df['error_type'] = prediction_df.apply(\n",
    "    lambda row: 'Unknown' if pd.isna(row['true_label']) else\n",
    "    ('TP' if row['predicted_class'] == 1 and row['true_label'] == 1 else\n",
    "     'TN' if row['predicted_class'] == 0 and row['true_label'] == 0 else\n",
    "     'FP' if row['predicted_class'] == 1 and row['true_label'] == 0 else 'FN'),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7c1618fa-182e-431d-ab18-eb0dd6c7d69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       138\n",
      "           1       0.84      0.76      0.80        42\n",
      "\n",
      "    accuracy                           0.91       180\n",
      "   macro avg       0.89      0.86      0.87       180\n",
      "weighted avg       0.91      0.91      0.91       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Remove rows where 'true_label' is NaN (they are not part of the evaluation)\n",
    "filtered_df = prediction_df.dropna(subset=['true_label']).copy()\n",
    "\n",
    "# Ensure 'true_label' and 'predicted_class' are integers\n",
    "filtered_df['true_label'] = filtered_df['true_label'].astype(int)\n",
    "filtered_df['predicted_class'] = filtered_df['predicted_class'].astype(int)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(filtered_df['true_label'], filtered_df['predicted_class'])\n",
    "\n",
    "# Define labels for the confusion matrix\n",
    "labelss = [\"Negative\", \"Positive\"]\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labelss, yticklabels=labelss)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(filtered_df['true_label'], filtered_df['predicted_class']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a08a89c3-1395-4c87-b472-fab64fd02a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_with_labels.to_csv('Y_with_labels.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "33aa358f-06be-4887-8f6c-00f543ab698c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['EX_ca2_e_forward', 'EX_ca2_e_reverse', 'EX_so4_e_forward',\n",
      "       'EX_so4_e_reverse', 'EX_co2_e_forward', 'EX_h2o_e_forward',\n",
      "       'EX_h2o_e_reverse', 'EX_h_e_forward', 'EX_h_e_reverse',\n",
      "       '2S6HCCi_forward',\n",
      "       ...\n",
      "       'KAS4_reverse', 'KAS6_forward', 'KAS6_reverse', 'KAS11_forward',\n",
      "       'KAS11_reverse', 'PGMT_forward', 'RNDR3_forward', 'TECA3S45_reverse',\n",
      "       'PGM_reverse', 'PHCYT_BS_forward'],\n",
      "      dtype='object', length=332)\n"
     ]
    }
   ],
   "source": [
    "print(X_with_labels.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e433bbd5-5db1-499f-90b1-c21c36a532d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [''] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33760\\1737374882.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_with_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gene_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Makes 'Gene' the index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   6118\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6119\u001b[0m                         \u001b[0mmissing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6122\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33mNone of \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m are in the columns\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6124\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6125\u001b[0m             \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [''] are in the columns\""
     ]
    }
   ],
   "source": [
    "X_with_labels.set_index('').to_csv('gene_data.csv')  # Makes 'Gene' the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f239af3-5556-44c7-89cc-3aa87426310f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
